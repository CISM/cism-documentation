
\section{Getting and Installing CISM}
\label{sec:getcode}

\href{http://oceans11.lanl.gov/cism/}{CISM}\footnote{\texttt{http://oceans11.lanl.gov/cism/}} is 
a relatively complex system of libraries and programs which build on other libraries. 
This section documents how to get CISM and its prerequisites, compile and install it. 
Many common problems and questions can be addressed using the 
\href{http://forum.cgd.ucar.edu/forums/ice-sheet-modeling-cism}{user discussion boards
\footnote{\texttt{http://forum.cgd.ucar.edu/forums/ice-sheet-modeling-cism}}}. 
A CISM users mailing list is also available and can be subscribed to by sending an email
to \texttt{cism-users@googlegroups.com}\footnote{Note that in order to subscribe from a non-Google email
address, you should first make sure to completely log out from any Google sites (e.g., Gmail) before sending 
your request. If you do not, it will automatically try to associate your request with your Gmail account instead.}
Please report unresolved problems using the bug reporting facility at the 
\href{https://github.com/CISM/CISM-release/issues}{CISM Github website}
\footnote{\texttt{https://github.com/CISM/CISM-release/issues}}. 

CISM is distributed as source code and a reasonably complete build environment is therefore required to compile the model. 
For UNIX and LINUX based systems (including Mac), the \href{http://www.cmake.org/}{Cmake} build system is used for building the model. 
Sample build scripts for a number of standard architectures are included, as are working build scripts 
for a number of large-scale, high-performance-computing architectures 
(e.g., \textit{Yellowstone} (CISL), \textit{Titan} (OLCF), and \textit{Hopper} (NERSC) ). 

There are two ways of getting the source code:

\begin{enumerate}

\item \href{https://github.com/CISM/CISM-release/archive/master.zip}{Download} a {\it released} version of the code as an archive (zip file) 

\item Clone the code from the \href{https://github.com/CISM/CISM-release}{CISM Github repository} using the following command: 
\texttt{git clone https://github.com/CISM/CISM-release/archive/master.zip}  
(Note that it is also possible to clone the repository using the SSH protocol 
if you have an SSH keypair generated on your computer and attached to your GitHub account.  
See the \href{https://github.com/CISM/CISM-release}{CISM Github repository wepage} and 
\href{https://help.github.com/articles/which-remote-url-should-i-use}{Github's help pages} for more information.)

\end{enumerate}

For beginners, downloading a zip archive of the latest release tag is recommended. 
More experienced users may want to download directly from the repository, 
as it will make updating the code easier in the future.

In either case, a Fortran90 compiler is required.  
Other software dependencies include the \href{http://www.unidata.ucar.edu/packages/netcdf/index.html}{netCDF} library, 
which CISM uses for data I/O, and a \href{http://www.python.org}{Python} distribution 
(used for analyzing dependencies and for automatically generating parts of the code) 
with a number of specific Python modules. Users who want to run the code in parallel will also need to install MPI, 
and users who want access to the \textit{Trilinos} solver library will need to 
download and build \textit{Trilinos}, and link to it when building CISM. 
Finally, you will need Cmake and Gnu Make to compile the code and link to the various third-party libraries. 

If you have not done so already, clone a tagged version of CISM or download an archive of the code, as noted above. Store the code or the unzipped, untarred archive in a location of your choice. More detailed build instructions, including instructions for the installation of supporting software, are given below.

% =====================================
% =====================================
\section{Installing Supporting Software for Basic (Serial) CISM}
% =====================================
% =====================================

Because the build process can be fairly complicated, we describe it in detail below, 
relying on the use of a package manager to handle many of the standard software dependencies. 
For each step we give specific instructions for both Mac OS X using MacPorts (in red boxes) and
Linux, specifically Ubuntu 12.10 (in blue boxes).  For users of different but similar systems,
hopefully these instructions can be used as a guide.

CISM can be installed in either a serial or parallel configuration. The parallel mode
allows the model to be run on multiple processors which can greatly speed up execution.
This is a common configuration to use on supercomputing clusters, but can also be 
convenient on modern desktops and laptops which often have four or more cores available.
However, the parallel build requires additional supporting software, so we first 
detail how to build serial CISM.  For newer users, it is recommended to first build
and successfully run serial CISM before moving on to the parallel build.  \textbf{Note
that currently, the Shallow Ice Approximation dycore (Glide) can only run on a single processor, 
even when the code is built with full parallel support.}

The instructions below assume the user has administrative privileges for
installing new software (note the extensive use of \texttt{sudo}).  
If you are working on a shared machine without
administrative privileges, you might proceed by assuming all needed packages are present and 
continue to the CISM installation section.  You can then refer back to this
section if you encounter problems to determine which packages might be missing or
problematic before contacting your system administrator.


\begin{mdframed}[style=mac] % V==============MAC================V
As mentioned above, we will take advantage of \href{http://www.macports.org/}{MacPorts}, 
a software package manager for Macs. This will allow us to install a significant amount 
of the base level software libraries needed by CISM with few complications. 

Go to \href{http://www.macports.org/install.php}{http://www.macports.org/install.php}, where you will find a range of ".pkg" installs available, including those for Mountain Lion, Lion, and Mavericks versions of Mac OS X. 

Note that installing MacPorts requires installing the Xcode developer toolset provided by Apple. Details of how to obtain Xcode vary by version of OS X. See MacPorts installation instructions and this \href{https://developer.apple.com/xcode/downloads/}{link} for details. Once Xcode is installed, you may need to additionally download the ``command line tool'' from the Preferences / Downloads menu of Xcode. 

Depending on computer security settings at your institution (firewalls, etc.), you may need to add proxy information so that Macports can communicate and download software from the outside world. All Macports software will be installed under \texttt{/opt/local/} by default. To add proxy information, after installing Macports, edit the configuration file at \texttt{/opt/local/etc/macports/macports.conf}. By searching for the text string "proxy", you will find the lines like \texttt{proxy\_http hostname:12345} near the bottom of the file. Enter your proxy information here as appropriate (e.g., \texttt{hostname:your\_host\_info\_here}).

If you have previously installed Macports but not updated it recently, it's generally a good idea to do so. Ideally, this should be done with admin or root privileges (you will be prompted to enter your password) using:

\texttt{sudo port selfupdate}

You will then be prompted to update any installed ports that are outdated, which you can do using:

\texttt{sudo port upgrade outdated}

To search for available software in Macports, type: 

\texttt{port search software-name}

Software is installed through Macports using the command:

\texttt{sudo port install software-name}

Additional Macports tips will follow inline below. Extensive documentation for Macports 
can be found at the \href{http://guide.macports.org}{Macports} website.
\end{mdframed}              % ^==============MAC================^


\begin{mdframed}[style=ubuntu] % V==============UBUNTU==========V
This Ubuntu instructions describe setting up supporting software and CISM in a Linux environment.
These instructions were written using a fresh installation of Ubuntu 12.10 but 
steps should be very similar in other versions of Ubuntu or other distributions of Linux.
Instructions make use of the command line tool for installing packages that comes with Ubuntu, 
\texttt{apt-get}.  Note that other package management tools (e.g., Software Center)
could also be used.

It's generally a good idea to do synchronize your local package index files before
installing new software using \texttt{apt-get}:

\texttt{sudo apt-get update}

To search for available packages, type:

\texttt{apt-cache search software-name}

And to see detailed information about a package, type:

\texttt{apt-cache show software-name}

Packages are installed through apt-get using the command:

\texttt{sudo apt-get install software-name}

Additional apt-get tips will follow inline below. Extensive documentation for apt-get 
can be found at the \href{https://help.ubuntu.com/community/AptGet/Howto}{Ubuntu} website
and through man pages (\texttt{man apt-get}).
\end{mdframed}                 % ^==============UBUNTU==========^



% =====================================
\subsection{Install git version control software}
% =====================================
If you intend to download the CISM code as a git repository, you will need the \texttt{git} package installed.
If you prefer to download a zipped archive of the code, this step can be skipped.


\begin{mdframed}[style=mac] % V==============MAC================V
Install git with:

\texttt{sudo port install git}
\end{mdframed}              % ^==============MAC================^


\begin{mdframed}[style=ubuntu] % V==============UBUNTU==========V
Install git with:

\texttt{sudo apt-get install git}
\end{mdframed}                 % ^==============UBUNTU==========^


% =====================================
\subsection{Install the GCC compiler suite}
% =====================================

The GCC compiler suite contains compilers for C, C++, and, optionally, Fortran.
Fortran and C compilers are required for serial CISM, and a C++ compiler is also
needed for parallel CISM.  CISM is known to work with GNU gfortran compilers, 
Intel ifort, and PGI.  In these instructions we will use GNU compilers because they
have been extensively tested with CISM and are freely available.  Advanced users
are welcome to use other compilers of their choosing.

CISM has been tested extensively with \texttt{gfortran} versions 4.5 and 4.6.
Newer (or older) versions may also work, although version 4.8 introduces a lot of 
new features that may uncover issues.

\begin{mdframed}[style=mac] % V==============MAC================V
Searching for gcc with \texttt{port search gcc} will return:

\begin{verbatim}
gcc44 @4.4.7 (lang) 
    The GNU compiler collection 
...
\end{verbatim}

in addition to a lot of other information on available Macports installs related to the GCC (Gnu) compiler suite. 

Where possible, we want to make sure that all other software we build and install 
with Macports uses the version of GCC we choose to install. To date, we've had success 
with GCC 4.6.3 (others make work as well but have not been tested). 
To install GCC 4.6.3 type:

\texttt{sudo port install gcc46}

You will see some verbose output telling you what is happening (downloading packages, 
expanding them, building, installing, checking, etc.). When the install is complete, you can type: 

\texttt{port installed} 

to see what packages you currently have installed. You should see \texttt{gcc46 \@4.6.3\_3 (active)}, 
in addition to any other packages you have installed (you may see software in addition to GCC 
that was installed because Macports takes into account any software dependencies for GCC as well). 

The ``(active)" description identifies which version of a particular package Macports 
currently thinks you want to use (e.g., you could also have another older GCC suite installed). 
To make sure the newly installed version is active, you would type:

\texttt{port select gcc}

which will return something like:

\begin{verbatim}
Available versions for gcc:
   gcc40
   gcc42
   mp-gcc46 (active)
   none
\end{verbatim}

This confirms that GCC 4.6 is active (the \texttt{mp} indicates a Macports version). 
It is possible that gcc46 will be listed as active when you type texttt{port installed}, 
but that mp-gcc46 will not be listed as active when you type \texttt{port select gcc}. 
If mp-gcc46 is not active as shown above, then you will need to select it using:

\begin{verbatim}
	sudo port select --set gcc mp-gcc46
\end{verbatim}

This will ensure that any generic call to gcc, gfortran, g++, will point to the libraries just installed.

\end{mdframed}              % ^==============MAC================^


\begin{mdframed}[style=ubuntu] % V==============UBUNTU==========V
GNU compilers may have come with your Linux distribution.  If not, they need to 
installed.  Ubuntu 12.10 comes with \texttt{gcc} installed but not \texttt{gfortran}.

Install \texttt{gfortran} with:

\texttt{sudo apt-get install gfortran}

Additional tools are needed for managing the build process.  \texttt{make} (specifically, GNU's gmake)
usually comes with a Linux distribution, but if not it should be installed.  On Ubuntu
(and other Debian systems) there is usually a package called \texttt{build-essential} that
includes a large collection of tools and libraries that are typically necessary
for compiling code.  Additionally, CISM uses the \texttt{cmake} build utility.

Install these tools with:

\texttt{sudo apt-get install build-essential cmake}

\end{mdframed}                 % ^==============UBUNTU==========^


% =====================================
\subsection{Install Build Tools}
% =====================================

Additional tools are needed for managing the build process.  \texttt{make} (specifically, GNU's gmake)
usually comes with Mac and Linux distributions, but if not it should be installed.  
Additionally, CISM uses the \texttt{cmake} build utility 
(\href{http://www.cmake.org/}{a cross-platform, open-source build system}).

\begin{mdframed}[style=mac] % V==============MAC================V

While you probably already have a version of \texttt{make} on your system, they may be out of date or conflict with other Macports installed software. These can be installed through Macports with the following commands: 

\begin{verbatim}
sudo port install gmake cmake
\end{verbatim}

In addition to the software installed above, you should now see something like the following when you type \texttt{port installed}:

\begin{verbatim}
  gmake @3.82_0 (active)
  cmake @2.8.10_1 (active)
\end{verbatim}
\end{mdframed}              % ^==============MAC================^



\begin{mdframed}[style=ubuntu] % V==============UBUNTU==========V
On Ubuntu (and other Debian systems) there is usually a package called \texttt{build-essential} 
that includes a large collection of tools and libraries that are typically necessary
for compiling code. Install these tools and \texttt{cmake} with:

\texttt{sudo apt-get install build-essential cmake}
\end{mdframed}                 % ^==============UBUNTU==========^


% =====================================
\subsection{Install NetCDF}
% =====================================
\label{sec:install-netcdf}
NetCDF stands for ``network Common Data Form'' libraries, which are a
 machine-independent format for representing scientific data.
This is required by CISM for performing input/output.  The NetCDF package you 
install must include Fortran libraries for CISM to compile (in some package managers,
the Fortran libraries are in a separate package).  There are substantial differences 
between versions 3.x and 4.x of NetCDF, but both version series should work with CISM. 
Note that it is also possible to download and compile NetCDF libraries manually, 
which may be preferred by some advanced users wanting to use a specific version.

It is also recommended that you install optional tools for working with NetCDF datafiles.
\href{http://meteora.ucsd.edu/~pierce/ncview_home_page.html}{\texttt{ncview}} is a very convenient tool for viewing NetCDF files.  (Some alternatives are to write Python or Matlab scripts or to use another
tool like Paraview.)  
\href{http://nco.sourceforge.net/}{\texttt{NCO}} (``netCDF Operators'') is a toolkit of command line tools
for manipulating and analyzing data stored in netCDF-accessible formats.

\begin{mdframed}[style=mac] % V==============MAC================V
To install NetCDF, use \texttt{sudo port install netcdf-fortran +gcc46}. 
Note that there are other versions of NetCDF available to install. It is important 
to choose the one with the ``Fortran" extension. The ``gcc46" syntax specifies a port ``variant". 
This tell Macports that, if there is a version of the selected software 
to install that is consistent with the GCC 4.6 compiler suite, then it should 
choose that one. Typing \texttt{port installed} should now include:

\begin{verbatim}
netcdf @4.3.2_0+dap+gcc46+netcdf4 (active)
netcdf-fortran @4.2_12+gcc46 (active)
\end{verbatim}

Note that the ``dap+netcdf4" comes along automatically. 

\textbf{Optional but recommended:} Tools for working with NetCDF data files.

\texttt{sudo port install ncview nco}

\end{mdframed}              % ^==============MAC================^


\begin{mdframed}[style=ubuntu] % V==============UBUNTU==========V
Install NetCDF libraries with:

\texttt{sudo apt-get install libnetcdf-dev}

\textbf{Optional but recommended:} Tools for working with NetCDF data files.

\texttt{sudo apt-get install netcdf-bin ncview nco}
\end{mdframed}                 % ^==============UBUNTU==========^



% =====================================
\subsection{Install Python and needed modules}
% =====================================
Python is used by CISM for autogenerating I/O code during compilation, and is also
used by most test case scripts to set up initial conditions and/or analyze and plot
results.  Only Python 2.7 has been tested.  Python 3 may work for some uses but is
likely to generate some errors due to extensive changes between versions 2 and 3.
Additionally, CISM makes use of a number of python modules:
\begin{itemize}
  \item \texttt{numpy} - required for generating many test case initial conditions
  \item \texttt{matplotlib} - used by some plotting scripts.  Not strictly necessary but required for those scripts to work properly.
  \item  a python netCDF I/O module.  Options are \texttt{netCDF4},  \texttt{Scientific.IO.NetCDF}, or \texttt{PyCDF}.  
\texttt{netCDF4} is the ideal choice, but it is often not available through Linux package managers and must be installed through a python package manager like pip or manually.
\texttt{PyCDF} is the least recommended option here because it is not entirely compatible with the others.  \texttt{Scientific.IO.NetCDF} is usually available through Linux package managers.
\end{itemize}


\begin{mdframed}[style=mac] % V==============MAC================V
While Mac OS X already comes with a working Python distribution, we will need 
additional modules that can sometimes be tricky to get working together correctly. 
We have successfully used both the 
\href{https://www.enthought.com/products/epd/}{Enthought} Python distribution 
(which is free for people associated with a university) and a version installed 
using Macports.  To install Enthought, follow the above link and follow their 
directions for obtaining and installing their distribution.
To install version 2.7 using Macports, along with the necessary 
additional modules, do the following 

\texttt{
sudo port install python27 py27-numpy py27-matplotlib py27-scientific py27-netcdf4
}

Note that the existence of two versions of python on your system can lead to confusion.
It is important that you leave the version of python that came supplied by Apple so that
your system has access to it.  However, you will want to be sure that CISM has access to
the new, more modern version of python you have installed.  In our experience,
this can be one of the most problematic part of the installation process.  There are two
approaches.  You can use \texttt{port select}:

\texttt{ sudo port select python python27}

You can check that Macports python is being by default by typing:

\texttt{which python}

and you should see: \texttt{/opt/local/bin/python}.  
If you instead see \texttt{/usr/bin/python} then the default Apple python is still 
the version that is being used on the command line.  If this happens, or if you 
encounter errors with this setup, an alternative approach is to modify the 
\texttt{PATH} variable in your \texttt{.bashrc} or similar environment settings script
to make sure that \texttt{/opt/local/bin} is before \texttt{/usr/bin} in your path.
\end{mdframed}              % ^==============MAC================^



\begin{mdframed}[style=ubuntu] % V==============UBUNTU==========V
Python generally comes with most Linux distributions.  If it is not present, it must be installed.
Often, there is an additional python development package that is necessary
when working with compiled code (tpyically called \texttt{python-dev} on Ubuntu).

Install python modules with:

\texttt{sudo apt-get install python-dev python-numpy python-matplotlib python-scientific}

\textbf{Optional:} Installing \texttt{netCDF4} python module.

Install pip (a tool for installing and managing Python packages):

\texttt{sudo apt-get install pip}

Install \texttt{netCDF4} using pip

\texttt{sudo -E pip install netcdf4}
\end{mdframed}                 % ^==============UBUNTU==========^



% =====================================
% =====================================
\section{Building serial CISM}
\label{serial-build}
% =====================================
% =====================================
At this point we are ready to build a \textit{serial} version of CISM and its linked libraries. While we ultimately want to build a 
version of the code that also runs in parallel, it is often useful to stop at this step to make sure everything is working. Then, if 
problems occur during the parallel build process (as they sometimes do), we know those problems have only occurred during 
the final step of the process.

If you have not already done so, obtain a copy of the source code following the instructions above in section \ref{sec:getcode}. Below, all 
paths starting with \texttt{./} indicate the root level of the source code directory. E.g., if you expanded your tar.gz archive into a main source code 
directory with the path \texttt{/usr/JohnDoe/CISM}, the \texttt{./} refers to the path \texttt{/usr/JohnDoe/CISM/}.  

Unlike in previous version of the code, the build system is now entirely based on Cmake 
(Autotools is no longer used). 

Build scripts are provided that should work for most standard Mac and Linux setups, 
as well as some supercomputing platforms on which CISM is commonly used.
All build scripts are located in the \texttt{./builds} directory from the root level of the code.
In general, change to the subdirectory that most closely matches your system and intended
build.

If you encounter an error when using the included scripts, you may need to modify some details, 
such as the location of your NetCDF libraries or your compiler names.  Other errors you might 
encounter may indicate that some of the supporting software (above) is missing.

%\textbf{SP: For the cake build to ''just work" (i.e., w/o setting an env vars, etc.), the only thing I had to do was to sym link the generic compiler names (e.g. gcc, g++, gfortran) and python in /opt/local/bin/ to the respective binary files there w/ a specific name (e.g., gcc-mp-6.4). Assuming one is in /opt/local/bin/, an example of that would be 'sudo ln -s ./gfortran-mp-4.6 ./gfortran'. This also assumes, that ones path has been pre-prended to look in /opt/local/ first, rather then /usr/local. This should have happened automatically when installing macports (it adds a line to your .profile script to cover this), but it might be worth mentioning explicitly (at the start?) as well. Note that after the fact, I found out that a more general / easier way of doing this might be to instead do, e.g., 'sudo port select --set gcc gcc46'. I have not tested this, but it is recommended (and seemed to work) for using of openmpi, e.g. by way of slaving the generic "mpi" to "openmpi-devel-gcc46-fortran". This is a faster way to do it, as it sets all the necessary sym links with a single command. I've already changed the gcc documentation above to reflect this. It would be good for someone else to confirm this if / when they do a clean install on a new machine.} 

\begin{mdframed}[style=mac] % V==============MAC================V
For building on a Mac, you should be able to build the by doing the following:

\begin{enumerate}
\item{change to the \texttt{./builds/mac-gnu-serial} directory from the root level of the code}
\item{configure the build using: \texttt{source mac-gnu-cmake-serial}}
\item{build the code using: \texttt{make -j X}, where the "X" refers to the number of processors available for use in the build (or just \texttt{make} if you only have one processor)}
\end{enumerate}
\end{mdframed}              % ^==============MAC================^


\begin{mdframed}[style=ubuntu] % V==============UBUNTU==========V
For building on a Linux platform, you should be able to build the by doing the following:

\begin{enumerate}
\item{change to the \texttt{./builds/linux-gnu-cism} directory from the root level of the code}
\item{configure the build using: \texttt{source linux-gnu-cism-cmake-serial}}
\item{build the code using: \texttt{make -j X}, where the "X" refers to the number of processors available for use in the build (or just \texttt{make} if you only have one processor)}
\end{enumerate}
\end{mdframed}                 % ^==============UBUNTU==========^

When the build completes, you can check for the executable driver by typing \texttt{ls cism\_driver} from within the build directory. The file \texttt{cism\_driver} is the executable you will link to when running the model, which is generally done using a symbolic link. For example, from the \texttt{./tests/higher-order/shelf/} directory, one would link to this executable using, 

\begin{verbatim}
ln -s ../../../builds/mac-gnu/cism_driver/cism_driver ./
\end{verbatim}

Discussion of running the executable for standard test cases is continued in section \ref{sec:testcases}). 


Advanced users may want more control over the build scripts.  There are a number of
build options used by cmake to customize the build.  You can manually modify the 
build scripts included with the code, or use the tool \texttt{ccmake} to 
interactively adjust build options (type \texttt{ccmake ../../} from any build directory
after having run the configure script once.  The available options are listed in Table \ref{cmake-options}.
Many of these options pertain to the parallel build which is discussed in more detail below.


\begin{table}
\begin{tabular}{ l | p{8cm} }
\hline
\texttt{CISM\_BUILD\_CISM\_DRIVER} & Toggle to build cism\_driver, on by default \\

\texttt{CISM\_BUILD\_EXTRA\_EXECUTABLES} & Toggle to build other executables, off by default \\

\texttt{CISM\_BUILD\_SIMPLE\_GLIDE} &  Toggle to build simple\_glide, on by default \\

\texttt{CISM\_COUPLED} & Toggle to build CISM for use with CESM, off by default \\

\texttt{CISM\_ENABLE\_BISICLES} & Toggle to build a BISICLES-capable cism\_driver, off by default  \\

\texttt{CISM\_FORCE\_FORTRAN\_LINKER} & Toggle to force using a fortran linker for building executables, off by default \\

\texttt{CISM\_GNU} & Toggle to set compilation flags needed for the gnu compiler, off by default \\

\texttt{CISM\_INCLUDE\_IMPLICIT\_LINK\_LIB} & Toggle to explicitly include the CMAKE\_Fortran\_IMPLICIT\_LINK\_LIBRARIES on the link line, on by default \\

\texttt{CISM\_MPI\_MODE} & Toggle to Configure with MPI: defaults to ON \\

\texttt{CISM\_NETCDF\_LIBS} &  Netcdf Library Names(s) \\

\texttt{GLIMMER\_NO\_EXECUTABLE} & Set to  ON  to just build libraries (default:OFF) \\

\texttt{CISM\_SERIAL\_MODE} & Toggle to Configure in Serial mode: defaults to OFF \\

\texttt{CISM\_SOURCEMOD\_DIR} &  Path to SourceMod directory of F90 files to replace CISM files \\

\texttt{CISM\_STATIC\_LINKING} &  Toggle to set static linking for executables, off by default \\

\texttt{CISM\_USE\_DEFAULT\_IO} &  Toggle to use default i/o files rather than running python script, off by default \\

\texttt{CISM\_USE\_GPTL\_INSTRUMENTATION} & Toggle to use GPTL instrumentation, on by default \\

\texttt{CISM\_USE\_MPI\_WITH\_SLAP} & Toggle to use mpi when using SLAP solver, only relevant if CISM\_SERIAL\_MODE=ON: defaults to OFF \\

\texttt{CISM\_USE\_TRILINOS} & Toggle to use Trilinos external solver libraries, on by default \\

\texttt{CMAKE\_VERBOSE\_CONFIGURE} & Verbose cmake configuration, on by default \\

%% older options below here %%

%\texttt{CISM\_USE\_CISM\_FRONT\_END} &  Toggle to use cism\_driver or cism\_cesm\_interface with cism\_front\_end, off by default \\

%\texttt{CISM\_BUILD\_GLINT} & Toggle to build glint, off by default \\

%\texttt{CISM\_BUILD\_GLINT\_EXAMPLE} & Toggle to build glint\_example, off by default \\

%% some probably not important options here %%

%\texttt{CISM\_NETCDFF\_FOUND} & Path to NetCDF libraries  \textbf{** do we need to include this here? **} \\                                                                                                                        

\hline
\end{tabular}
  \caption{Available \texttt{cmake} settings for configuring the CISM build process}
  \label{cmake-options}
\end{table}

Additionally there are standard cmake options that can be set (e.g., \texttt{CMAKE\_C\_COMPILER}, \texttt{CMAKE\_Fortran\_COMPILER}, etc.).  Many of these are \href{http://www.cmake.org/Wiki/CMake_Useful_Variables}{documented in the cmake docmentation}.



% =====================================
% =====================================
\section{Supporting software needed for parallel CISM}
% =====================================
% =====================================
To build parallel CISM, MPI compilers and libraries are required.  
Only the higher-order dycore (Glissade) can run in parallel.  (There also is an
additional higher-order dycore called Glam that can be run in parallel, but it is used
for development and testing and is not supported for scientific applications.)

Additionally, you may choose to include the Trilinos package of external solver libraries.  
These are not required, but for some problems use of Trilinos may provide better
performance and stability than the native solvers.  Note that Trilinos can also technically be 
used with a serial build, but this configuration is not supported or recommended.

% =====================================
\subsection{Install MPI}
% =====================================
MPI (Message Passing Interface) libraries and compilers are necessary for compiling parallel CISM.  
These libraries are used for handling parallel communications when running the 
code on multiple processors. A more complete description of possible parallel 
model configurations is give in Chapter \ref{ch:runcism}. 
(for example, some test cases and configurations when running the shallow-ice 
momentum balance model are not fully supported in parallel). 

\begin{mdframed}[style=mac] % V==============MAC================V
It is likely that you already have versions of MPI installed on your system, 
but they may be out of date or not compatible with the other libraries we have 
and will be installing. Using Macports, the Mpich version of MPI is known 
to work when building CISM.

First, check Macports for available versions of Mpich using \texttt{port search mpich*}. We want 
the version that is compatible with our GCC compiler suite, so we type: 

\begin{verbatim}
	sudo port install mpich-devel-gcc46 +fortran
\end{verbatim}

To make sure this is active, type 
\begin{verbatim}
	port installed mpi*
\end{verbatim}

, which should return, 

\begin{verbatim}
     mpich-devel-gcc46 @3.2a1_0+fortran (active)
\end{verbatim}

As when installing the GCC compilers, we want to make sure any generic call to MPI points to Mpich. This 
can be done with the following command:

\begin{verbatim}
	sudo port select --set mpi mpich-devel-gcc46-fortran
\end{verbatim}

\end{mdframed}              % ^==============MAC================^



\begin{mdframed}[style=ubuntu] % V==============UBUNTU==========V
Install OpenMPI with:

\texttt{sudo apt-get install openmpi-bin}
\end{mdframed}                 % ^==============UBUNTU==========^



% =====================================
\subsection{Install Trilinos solver libraries}
% =====================================

Trilinos is a modern, open source, C++ based library of parallel nonlinear and linear solvers, 
preconditioning and mesh-partitioning tools, and much more. It can be downloaded 
\href{trilinos.sandia.gov/download/}{here}\footnote{trilinos.sandia.gov/download/}
 (the software is free, but you are required to enter your email address to download it). 
The documentation below assumes that you are working with version 11.10.* and was specifically 
tested using version 11.10.2. 

Building Trilinos requires Cmake version 2.8 or later, which ideally you've already 
installed as discussed above. Note that Trilinos is not needed to run the default 
parallel, higher-order momentum balance model, but it may be useful for tackling 
more difficult problems or for debugging in cases where the native Fortran solvers 
fail to converge.

Note that build instructions for Trilinos on Mac and Linux are very similar, so users
of both systems can follow the primary instructions below, except where noted.

Trilinos requires both (1) an ``out-of-source build'' and (2) an ``out-of-build installation''. 
This means that you cannot build the code in the same directory where the source code lives, 
and you cannot install the libraries in the same directory where you build the code 
(older versions of Trilinos required an out-of-source build but not and out-of-build installation). 
The easiest way to satisfy this requirement is to have separate ``source'', ``build'' and 
``install'' directories in the location where you want to install the code, 
for example, in \texttt{/usr/local/}, you could set up the following three directories:

\begin{verbatim}
	trilinos-11.10.2-Source/
	trilinos-11.10.2-Build/
	trilinos-11.10.2-Install/
\end{verbatim}

The ``source'' directory will be created on its own when you uncompress the tar.gz archive 
that you download (you do not have to keep the source code where you build and install 
the Trilinos libraries but you will need to remember the path to where that source code 
lives on your computer). 

To configure the Trilinos build, you will need to execute a Cmake configure script. 
Sample configure scripts for a number of standard platforms are included in the ``sampleScripts''
directory under the root level of the Trilinos source code. 
Additionally, the CISM code includes examples of Trilinos configure scripts (``do-configure'') 
for use with CISM for both Linux and Mac platforms in the 
\texttt{./utils/trilinos\_config\_scripts\_examples} directory. 
We recommend starting with one of those scripts and modifying it as
necessary to work on your system \footnote{If you are following the above installation instructions for
Mac exactly, then the configure script 
\texttt{./utils/trilinos\_config\_scripts\_examples/do-configure-Trilinos-11.10.2-for-Mac-10.9.4} should 
work with very few minor modifications.}.

Note that the paths to both the ``source'' and ``install'' directories are specified within the ``do-configure'' scripts. In these instructions, those directories are both assumed to live within \texttt{/usr/local/},
but other locations are fine to use too (e.g., in your home/User directory).

\begin{mdframed}[style=mac] % V==============MAC================V
Also note the explicit path in the MPI lines, e.g.,

\begin{verbatim}
-D MPI_EXEC="/opt/local/mpiexec" \
\end{verbatim}

Since some Macs may come with their own pre-installed OpenMPI libraries, it is important here to specify the path to the version we previously installed using Macports.
\end{mdframed}              % ^==============MAC================^

Find the example script most appropriate for your system, copy it to the \texttt{trilinos-11.10.2-Build} directory, and modify it if necessary (e.g., adjust paths, compiler locations, etc.).
Execute it with: 

\texttt{source ./do-cmake}\footnote{Note that here we've assumed that the name of the configure script is `do-cmake'. This script name may differ depending on what you have called it or if you've copied and modified one of the scripts from \texttt{./utils/trilinos\_config\_scripts\_examples}.}

from within your \texttt{trilinos-11.10.2-Build} directory. Note that depending on where you are building and installing the code, you may need to have administrative privileges (in which case you would type \texttt{sudo source ./do-cmake}). If the configure step was successful, you should see the following displayed on your screen:

\begin{verbatim}
...
Processing enabled package: [PACKAGE NAME]
...

Exporting library dependencies ...

Finished configuring Trilinos!

-- Configuring done
-- Generating done
-- Build files have been written to: /usr/local/trilinos-11.10.2-Build
\end{verbatim}

It is a good idea to scan the output while the ``do-cmake'' script is executing, 
for example to ensure the configure process is picking up the compilers you specified 
(e.g., it is using the Macports versions as opposed to some Mac default versions that 
might also be on your system). Once the code is configured successfully, build the libraries 
from within the \texttt{trilinos-11.10.2-Build} directory by typing:

\texttt{make} (or \texttt{sudo make} if necessary) 

For multiprocessor machines, the build process can be sped up significantly using 
the ``-j''command as described above for building serial CISM:

\texttt{make -j X}

where ``X'' is the number of cores available on your machine (e.g. \texttt{make -j 4} 
for a 2 processor, dual-core machine).

Building Trilinos can take a long time (e.g., an hour or more), depending on your machine, 
the number of processors used for the build, and the number and type of libraries 
you are installing. Once you have built the code, we highly recommend testing it 
using:

 \texttt{make test} 

(note that the

\begin{verbatim}
Trilinos_ENABLE_TESTS:BOOL
\end{verbatim}

variable in the do-cmake script can be set to ``OFF''to disable building of the tests). 
Screen output will tell you if and how many tests failed. In general, we have seen 
one or two tests fail while still having a perfectly good and working Trilinos library. 
Query the \href{file:///Users/sprice/cism-website/documentation.html}{CISM users / developers lists}
\footnote{file:///Users/sprice/cism-website/documentation.html} if you have questions 
about specific Trilinos tests failing \footnote{We have seen a number of tests ``fail" while still giving a perfectly 
functional Trilinos library. In general, if the number of tests passed is above 90\%, the library will likely work
fine with CISM.}.

\begin{mdframed}[style=mac] % V==============MAC================V
Note that on a Mac, MPI tests have been known to trigger a dialog box from the firewall. 
With more than 300 tests, these messages popping up continually can make it impossible 
to use you computer until the tests complete. To keep them from appearing, you can temporarily 
turn off your firewall under ``System Preferences'' (Security $>$ Firewall $>$ Stop). 
Be sure to turn the firewall back on when the tests are complete!
\end{mdframed}              % ^==============MAC================^

After running the tests, you will need to install Trilinos using:

 \texttt{make install}

This will build the actual Trilinos libraries in the path specified in the

\begin{verbatim}
-D CMAKE_INSTALL_PREFIX:PATH=/path
\end{verbatim} 

line of your ``do-cmake'' script (above). For this example, those libraries will be 
installed in: \texttt{/usr/local/trilinos-11.10.2-Install}

After successfully building Trilinos, create an environment variable called \texttt{CISM\_TRILINOS\_DIR}
so the CISM build process can find the Trilinos installation.  For example, if you 
are using the bash shell and your current directory is the Trilinos install directory, you can do:
\begin{verbatim}
export CISM_TRILINOS_DIR=$PWD
\end{verbatim}
(Note that you may prefer to modify your .bashrc or .bash\_profile (or similar)
to set this environment variable on every login.)

Alternatively, you can modify the CISM parallel build script (below) so that the line:
\begin{verbatim}
-D CISM_TRILINOS_DIR=$CISM_TRILINOS_DIR \
\end{verbatim}
is set to the Trilinos installation directory.





% =====================================
% =====================================
\section{Building parallel CISM}
% =====================================
% =====================================

The procedure for building parallel CISM is nearly identical to the serial build (above).
The build script for parallel CISM for a Mac is located at \texttt{builds/mac-gnu/mac-gnu-cmake}, 
while the build script for Linux is located at \texttt{builds/linux-gnu-cism/linux-gnu-cism-cmake}.
From the appropriate directory, run:

\texttt{ source mac-gnu-cmake} or \texttt{ source linux-gnu-cism-cmake}

Once the configuration step completes successfully, you can compile the code as before with:

\texttt{make}

or

\texttt{make -j 4}

if you have 4 processors available (or as many processors as you would like to use).

See Section \ref{serial-build} for details about customizing the build process.


% =====================================
% =====================================
\section{Next Steps}
% =====================================
% =====================================

Now that you have successfully built the code, you can proceed to Chapters \ref{ch:modelingintro} and \ref{ch:higher-order} to learn more detailed 
information about ice sheet modeling, to Chapters \ref{ch:glide} and \ref{ch:glissade} to learn more about the various model approximations 
available through CISM, or you can proceed to Chapter \ref{ch:tests} to learn how to run and examine some standard model test cases.  


