
\section{Velocity Solver}
\label{sc:glissade-velocity}

Glissade computes the ice velocity by solving an appropriate
approximation of the Stokes equations, given the 2D surface elevation and thickness fields,
the 3D temperature field, and relevant boundary conditions.
The directory \texttt{libglissade} contains the primary higher-order velocity module,
\texttt{glissade\_velo\_higher.F90}, along with supporting modules for the various solver options.
Section \ref{sc:glissade-blatter-pattyn} describes assembly and solution of the matrix problem for the 
3D first-order Blatter-Pattyn approximation.  
The following sections discuss simpler approximations, including the shallow-ice, shallow-shelf,
and L1L2 approximations.

\subsection{Blatter-Pattyn approximation}
\label{sc:glissade-blatter-pattyn}

The basic equations of the Blatter-Pattyn approximation in Cartesian coordinates, repeated from 
Section \ref{sc:higher-order-mom}, are 

\begin{equation}
  \label{gliss.eq.stress_balance}
  \begin{split}
    x: \quad \frac{\partial }{\partial x}\left( 2 \eta \left(2\frac{\partial u}{\partial x} +  \eta \frac{\partial v}{\partial y} \right) \right) 
    + \frac{\partial }{\partial y}\left( \eta \left( \frac{\partial u}{\partial y} + \frac{\partial v}{\partial x} \right) \right) 
    +\frac{\partial }{\partial z}\left( \eta \frac{\partial u}{\partial z} \right) = \rho g\frac{\partial s}{\partial x}, \\
    y: \quad \frac{\partial }{\partial y}\left( 2 \eta \left( 2\frac{\partial v}{\partial y} + \eta \frac{\partial u}{\partial x} \right) \right) 
    + \frac{\partial }{\partial x}\left( \eta \left( \frac{\partial u}{\partial y} + \frac{\partial v}{\partial x} \right) \right) 
    +\frac{\partial }{\partial z}\left( \eta \frac{\partial v}{\partial z} \right) = \rho g\frac{\partial s}{\partial y},  \\
  \end{split}
\end{equation}

\noindent
where $u$ and $v$ are the components of horizontal velocity, $\eta$ is the effective viscosity, $s$ is the ice surface elevation,
$\rho$ is the density of ice (assumed constant), and $g$ is gravitational acceleration.  

As in Glide, the equations are discretized on a structured 3D mesh.
In the map plane the mesh consists of rectangular \textit{cells}. These cells form an unstaggered 2D grid 
of dimension $(nx,ny)$ (thus the number of cells is $(nx)(ny)$), together with a staggered grid of dimension $(nx-1,ny-1)$.
The corners of each cell (where four rectangles meet) are called \textit{vertices}.
The vertical \textit{levels} of the mesh are based on a terrain-following sigma coordinate system. 
We define $\sigma = (s-z)/H$, where $H$ is the ice thickness, with $\sigma = 0$ at the top surface and $\sigma = 1$ at the bed. 
There are $nz$ levels in the vertical direction, with $nz-1$ \textit{layers} between these levels.
An \textit{element} is the region associated with a particular cell and layer; there are
$(nx)(ny)(nz-1)$ elements on the mesh.  A \textit{node} is a point where eight elements intersect (or where four elements
intersect at the upper or lower surface). There are $(nx-1)(ny-1)(nz)$ nodes on the mesh.

Scalar 2D fields such as $H$ and $s$ are defined for each cell.
Scalar 3D fields such as ice temperature $T$ lie at the center of each element (i.e., at the midpoint of each layer
associated with  each cell). Gradients of 2D scalar fields (e.g., the surface slope $\nabla s$) are defined at vertices.
The velocity components $u$ and $v$ live at nodes.

For problems solved in parallel, the domain is partitioned among multiple processors.  
Let $nx_{\textrm{local}}$ and $ny_\textrm{{local}}$ be the
number of locally owned cells on each processor.  Each processor holds data for two rows of halo cells 
(i.e., cells belonging to other processors) surrounding the block of locally owned cells.
Thus the 2D grid on a given processor has dimensions $(nx_{\textrm{local}} + 2, ny_{\textrm{local}} + 2)$.
Each locally owned cell is associated with a locally owned vertex lying at the northeast (upper right) corner
of the cell.

An \textit{active cell} is a cell that borders a locally owned vertex, whose ice thickness exceeds a minimum threshold.  
Each active cell is associated with a column of $nz-1$ \textit{active elements}.  
(All the data in a given column resides on a single processor.)
An \textit{active vertex} is any vertex of an active cell.  Each active vertex is
associated with $nz$ active nodes, including nodes at the surface and bed.

The effective viscosity is defined in each active element by

\begin{equation}
  \label{gliss.eq.effective_viscosity}
  \eta \equiv \frac{1}{2} A^{\frac{-1}{n}} \dot{\varepsilon }_{e}^{\frac{1-n}{n}},
\end{equation}

\noindent
where $A$ is the temperature-dependent rate factor in Glen's flow law, and $\dot{\varepsilon }_{e}$ is the effective strain rate,
given in the Blatter-Pattyn approximation by 

\begin{equation}
  \label{gliss.eq.effective_strain_rate}
        {{\dot{\varepsilon }}^{2}}_{e}={{\dot{\varepsilon }}^{2}}_{xx}+{{\dot{\varepsilon }}^{2}}_{yy}+{{\dot{\varepsilon }}_{xx}}{{\dot{\varepsilon }}_{yy}}+{{\dot{\varepsilon }}^{2}}_{xy}+{{\dot{\varepsilon }}^{2}}_{xz}+{{\dot{\varepsilon }}^{2}}_{yz},
\end{equation}

\noindent
where

\begin{equation}
  \dot{\varepsilon }_{ij} = \frac{1}{2}\left( \frac{\partial u_{i}}{\partial x_{j}} + \frac{\partial u_{j}}{\partial x_{i}} \right).
\end{equation}

\noindent
To compute $A(T)$, we assume an Arrhenius relationship:

\begin{equation}
  \label{gliss.eq.arrhenius}
  A(T_{\mathrm{pmp}})=a e^{-Q/RT_{\mathrm{pmp}}},
\end{equation}

\noindent
where $T_{\mathrm{pmp}}$ is the pressure melting point temperature,
$a$ is a temperature--independent material constant (given by \citet{PatersonBudd:1982}),
$Q$ is the activation energy for creep and $R$ is the universal gas constant.

Given $T$, $s$, $H$, and an initial guess for $u$ and $v$, the problem is to solve Eq. \eqref{gliss.eq.stress_balance}
for $u$ and $v$ at each active node.  (At inactive nodes we set $u=v=0$.)  This problem can be written in the form

\begin{equation}
  \label{gliss.eq.matrix_full}
  \mathbf{A} \mathbf{x} = \mathbf{b},
\end{equation}

\noindent
or more fully,

\begin{equation}
  \label{gliss.eq.matrix}
  \begin{matrix}
    \left[ \begin{matrix}
        \mathbf{A}_{\mathbf{uu}} & \mathbf{A}_{\mathbf{uv}}  \\
        \mathbf{A}_{\mathbf{vu}} & \mathbf{A}_{\mathbf{vv}}  \\
      \end{matrix} \right]\left[ \begin{matrix}
        \mathbf{u}  \\
        \mathbf{v}  \\
      \end{matrix} \right]=\left[ \begin{matrix}
        \mathbf{b}_{\mathbf{u}}  \\
        \mathbf{b}_{\mathbf{v}}  \\
      \end{matrix} \right]. \\ 
    \\ 
%    \mathbf{A}_{\mathbf{uu}}\mathbf{u} + \mathbf{A}_{\mathbf{uv}}\mathbf{v} =\mathbf{b}_{\mathbf{u}},
%    \quad \quad \mathbf{A}_{\mathbf{vu}}\mathbf{u} + \mathbf{A}_{\mathbf{vv}}\mathbf{v} =\mathbf{b}_{\mathbf{v}}. \\ 
  \end{matrix}
\end{equation}

\noindent
Eq. \eqref{gliss.eq.matrix} shows the four parts of the global matrix $\mathbf{A}$,
with the solution and right-hand-side vectors separated into $u$ and $v$ components.
In Glissade, $\mathbf{A}$ is always symmetric and positive-definite.

Since $\mathbf{A}$ depends (through $\eta$) on $u$ and $v$, the problem is nonlinear and must be solved iteratively
(see Section~\ref{sc:fixed-point}).
For each nonlinear iteration, Glissade computes the 3D $\eta$ field based on the
current guess for the velocity field and solves a linear problem of the form \eqref{gliss.eq.matrix}.
Then $\eta$ is updated and the process is repeated until the solution converges to within a given tolerance.
This procedure is known as Picard iteration.

The following sections describe how the matrix equations are assembled and solved. 

\subsubsection{Assembly}
\label{sec:glissade-assembly}
The coupled PDEs \eqref{gliss.eq.stress_balance} are discretized using the finite-element method.
Here we give a detailed but non-rigorous description of the method as applied to the Blatter-Pattyn
approximation on the CISM mesh.
We refer the reader to standard texts \citep[e.g.,][]{Hughes2000} for a full discussion of finite elements.

The PDEs, with appropriate boundary conditions, are converted to a system of algebraic equations
by dividing the full domain into subdomains (i.e., elements), representing the velocity solution on each element,
and integrating over elements. On the CISM mesh, the elements are hexahedra (rectangles
in map view), each of which has eight nodes shared with its neighbors.
The solution is approximated as a sum over basis functions $\varphi$. 
Each active node is associated with a basis function whose value is $\varphi = 1$ at that node,
with $\varphi = 0$ at all other nodes. The solution at a point
within an element can be expanded in terms of basis functions and nodal values:

\begin{equation}
\label{gliss.eq.velo_expansion}  
   u(x,y,z) = \sum\limits_{n}{{{\varphi }_{n}(x,y,z)}{{u}_{n}}}, \quad 
   v(x,y,z) = \sum\limits_{n}{{{\varphi }_{n}(x,y,z)}{{v}_{n}}},  \\
\end{equation}

\noindent
where the sum is over the nodes of the element, $u_n$ and $v_n$ are nodal
values of the solution, and $\varphi_n$ varies smoothly between 0 and 1 within the element.
The fact that $\varphi = 0$ except in a small region ensures that the sum includes only
as many terms as there are nodes per element.

Glissade uses standard finite-element techniques to represent the PDE on each element and assemble
the element equations into a global set of algebraic equations of the form \eqref{gliss.eq.matrix}.
The scheme is formally equivalent to that described by \citet{Perego2012} (henceforth PGB).
Eq. \eqref{gliss.eq.stress_balance} can be written as

\begin{equation}
  \label{gliss.eq.Perego12}
  \begin{split}
    -\nabla \cdot (2\eta {{{\dot{\varepsilon }}}_{1}}) = -\rho g\frac{\partial s}{\partial x}, \\
    -\nabla \cdot (2\eta {{{\dot{\varepsilon }}}_{2}}) = -\rho g\frac{\partial s}{\partial y}, \\
  \end{split}
\end{equation}

\noindent
where

\begin{equation}
  \label{gliss.eq.Perego13}
  {{{\dot{\varepsilon }}}_{1}}=\left[ \begin{matrix}
      2{{{\dot{\varepsilon }}}_{xx}}+{{{\dot{\varepsilon }}}_{yy}} \\ 
      {{{\dot{\varepsilon }}}_{xy}} \\ 
      {{{\dot{\varepsilon }}}_{xz}} \\ 
    \end{matrix} \right], \quad
  {{{\dot{\varepsilon }}}_{2}}=\left[ \begin{matrix}
      {{{\dot{\varepsilon }}}_{xy}} \\ 
      {{{\dot{\varepsilon }}}_{xx}}+2{{{\dot{\varepsilon }}}_{yy}} \\ 
      {{{\dot{\varepsilon }}}_{yz}} \\ 
    \end{matrix} \right].  \\
\end{equation}

\noindent
(These are Eqs. 12 and 13 in PGB.)  We rewrite the equations in \textit{weak form} (see PGB Eq. 15), which
is obtained by multiplying \eqref{gliss.eq.Perego12} by the basis functions and integrating over the domain, using 
integration by parts to eliminate the second derivative:

\begin{equation}
  \label{gliss.eq.weak_form}
  \begin{split}
    x: \quad \int\limits_{\Omega } {2\eta {{{\dot{\varepsilon }}}_{1}}(u,v)\cdot \nabla {{\varphi }_{1}} \text{ d}\Omega }
      + \int\limits_{{\Gamma }_{B}} {\beta u{{\varphi }_{1}} \text{ d}\Gamma} 
      + \int\limits_{{\Gamma }_{L}} {p n_1 {{\varphi }_{1}} \text{ d}\Gamma}
      + \int\limits_{\Omega } {\rho g\frac{\partial s}{\partial x}{{\varphi }_{1}} \text{ d}\Omega}
      = \text{0},  \\
    y: \quad \int\limits_{\Omega } {2\eta {{{\dot{\varepsilon }}}_{2}}(u,v)\cdot \nabla {{\varphi }_{2}} \text{ d}\Omega }
      + \int\limits_{{\Gamma }_{B}} {\beta u{{\varphi }_{2}} \text{ d}\Gamma} 
      + \int\limits_{{\Gamma }_{L}} {p n_2 {{\varphi }_{2}} \text{ d}\Gamma}
      + \int\limits_{\Omega } {\rho g\frac{\partial s}{\partial y}{{\varphi }_{2}} \text{ d}\Omega}
      = \text{0},  \\
  \end{split}
\end{equation}

\noindent
where $\Omega$ represents the domain volume, $\Gamma_{B}$ denotes the lower boundary, $\Gamma_{L}$ denotes the lateral
boundary (e.g., the calving front of an ice shelf), $\beta$ is a basal traction parameter, $p$ is the pressure at the 
lateral boundary, and $n_1$ and $n_2$ are components of the normal to $\Gamma_L$.
These equations can also be obtained from a variational principle as described by \citet{DUKOWICZ:2010wb}.

The four terms on the LHS of \eqref{gliss.eq.weak_form} describe internal ice streses, basal friction, lateral pressure,
and the gravitational driving force, respectively.  Next we describe how these terms are summed over elements
and assembled into the global matrix $\mathbf{A}$ and right-hand side vector $\mathbf{b}$.

\paragraph{Internal ice stresses.}

We start with the internal stress term, which is the most complex.
We rewrite the first term on the LHS of \eqref{gliss.eq.weak_form} in terms of velocity components:

\begin{equation}
  \label{gliss.eq.weak_form_velo}
  \begin{aligned}
    & x: \int\limits_{\Omega }{2\eta \left[ \begin{matrix}
          2\frac{\partial u}{\partial x}+\frac{\partial v}{\partial y} & \frac{1}{2}\left( \frac{\partial u}{\partial y}+\frac{\partial v}{\partial x} \right) & \frac{1}{2}\frac{\partial u}{\partial z}  \\
\end{matrix} \right]}\left\{ \begin{matrix}
      \frac{\partial \varphi }{\partial x}  \\[6pt]
      \frac{\partial \varphi }{\partial y}  \\[6pt]
      \frac{\partial \varphi }{\partial z}  \\
    \end{matrix} \right\},  \\
    & y: \int\limits_{\Omega }{2\eta \left[ \begin{matrix}
          \frac{1}{2}\left( \frac{\partial u}{\partial y}+\frac{\partial v}{\partial x} \right) & 2\frac{\partial v}{\partial y}+\frac{\partial u}{\partial x} & \frac{1}{2}\frac{\partial v}{\partial z}  \\
        \end{matrix} \right]}\left\{ \begin{matrix}
      \frac{\partial \varphi }{\partial x}  \\[6pt]
      \frac{\partial \varphi }{\partial y}  \\[6pt]
      \frac{\partial \varphi }{\partial z}  \\
    \end{matrix} \right\},  \\
  \end{aligned}
\end{equation}

\noindent
where brackets are used for row vectors and braces for column vectors.
Glissade evaluates \eqref{gliss.eq.weak_form_velo} for each active element.  Recall that hexahedral elements have eight nodes,
with $u$ and $v$ to be determined at each active node.
Inserting the velocity expressions \eqref{gliss.eq.velo_expansion} in \eqref{gliss.eq.weak_form_velo}, we obtain

\begin{equation}
  \label{gliss.eq.element_matrix}
  \begin{split}
    x: \int\limits_{\Omega }{2\eta \left( \frac{\partial {{\varphi }_{i}}}{\partial x}\left( 2\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{u}_{j}} \right\}+\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{v}_{j}} \right\} \right)+\frac{\partial {{\varphi }_{i}}}{\partial y}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{u}_{j}} \right\}+\frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{v}_{j}} \right\} \right)+\frac{\partial {{\varphi }_{i}}}{\partial z}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial z} \right]\left\{ {{u}_{j}} \right\} \right) \right)},  \\
    y: \int\limits_{\Omega }{2\eta \left( \frac{\partial {{\varphi }_{i}}}{\partial y}\left( 2\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{v}_{j}} \right\}+\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{u}_{j}} \right\} \right)+\frac{\partial {{\varphi }_{i}}}{\partial x}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{v}_{j}} \right\}+\frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{u}_{j}} \right\} \right)+\frac{\partial {{\varphi }_{i}}}{\partial z}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial z} \right]\left\{ {{v}_{j}} \right\} \right) \right)}.  \\
  \end{split}
\end{equation}

\noindent
Each row or column vector has eight terms, one for each node of the element.
These terms can be evaluated to form a set of four $8\text{x}8$ element matrices.
Each row of an element matrix is associated with $u$ or $v$ at a given node.  The columns in that row contain terms
linking that node to $u$ or $v$ at the other nodes of the element (with the diagonal term linking the node to itself).  

In the $x$ component of \eqref{gliss.eq.element_matrix}, 
the terms that multiply $u_j$ are given by
 
\begin{equation}
  \label{gliss.eq.matrix_Kuu}
  \int\limits_{\Omega }{\eta \left( 4\frac{\partial {{\varphi }_{i}}}{\partial x}\frac{\partial {{\varphi }_{j}}}{\partial x} +
    \frac{\partial {{\varphi }_{i}}}{\partial y}\frac{\partial {{\varphi}_{j}}}{\partial y} + 
    \frac{\partial {{\varphi }_{i}}}{\partial z}\frac{\partial {{\varphi }_{j}}}{\partial z} \right)}d\Omega
\end{equation}

\noindent
Letting $i$ and $j$ range from 1 to 8, \eqref{gliss.eq.matrix_Kuu} gives the 64 terms of the $8\text{x}8$ element matrix $\mathbf{K_{uu}}$,
which links the $u$ value at each node to the $u$ values at all eight nodes.
Similarly, the 64 terms of element matrix $\mathbf{K_{uv}}$, which links $u$ at each node to $v$ at each of the eight nodes,
are given by

\begin{equation}
  \label{gliss.eq.matrix_Kuv}
  \int\limits_{\Omega }{\eta \left( 2\frac{\partial {{\varphi }_{i}}}{\partial x}\frac{\partial {{\varphi }_{j}}}{\partial y}+\frac{\partial {{\varphi }_{i}}}{\partial y}\frac{\partial {{\varphi }_{j}}}{\partial x} \right)}d\Omega
\end{equation}
%
Likewise, two $8\text{x}8$ matrices are associated with the $y$ component of \eqref{gliss.eq.element_matrix}.  
The terms of $\mathbf{K_{vu}}$, which connects $v$ at each node to $u$ at each of eight nodes, are given by

\begin{equation}
  \label{gliss.eq.matrix_Kvu}
  \int\limits_{\Omega }{\eta \left( 2\frac{\partial {{\varphi }_{i}}}{\partial y}\frac{\partial {{\varphi }_{j}}}{\partial x}+\frac{\partial {{\varphi }_{i}}}{\partial x}\frac{\partial {{\varphi }_{j}}}{\partial y} \right)}d\Omega
\end{equation}

\noindent
Finally, the terms of $\mathbf{K_{vv}}$, which links $v$ at each node to $v$ at each of eight nodes, are given by

\begin{equation}
  \label{gliss.eq.matrix_Kvv}
  \int\limits_{\Omega }{\eta \left( 4\frac{\partial {{\varphi }_{i}}}{\partial y}\frac{\partial {{\varphi }_{j}}}{\partial y}+\frac{\partial {{\varphi }_{i}}}{\partial x}\frac{\partial {{\varphi}_{j}}}{\partial x}+\frac{\partial {{\varphi }_{i}}}{\partial z}\frac{\partial {{\varphi }_{j}}}{\partial z} \right)}d\Omega
\end{equation}

Because of the symmetry of the underlying PDEs, $\mathbf{K_{uu}}$ and $\mathbf{K_{vv}}$ are symmetric,
and $\mathbf{K_{uv}} = \mathbf{K_{vu}}^{T}$.  Note that $\mathbf{K_{vv}}$ can be obtained from $\mathbf{K_{uu}}$, 
and $\mathbf{K_{vu}}$ from $\mathbf{K_{uv}}$, by exchanging $x$ and $y$.  The terms
containing $z$ (i.e., the vertical shear stresses associated with the shallow-ice approximation)
appear only in $\mathbf{K_{uu}}$ and $\mathbf{K_{vv}}$.  The terms containing $x$ and $y$ (i.e.,
the membrane stresses) appear in all four element matrices.

Eqs. \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv} lie at the heart of the code. 
Together with the expressions for the effective viscosity $\eta$ (discussed below),
these expressions contain the physical contents of the Blatter-Pattyn approximation. 

In the weak form of the equations, each of the 64 coefficients in each
element matrix must be integrated over the element.  (Since $\varphi$ varies over the element,
the integrands in \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv} 
have a different value at each point.)  
This is done for a given element by evaluating the integrand at each of 
eight \textit{quadrature points} and summing over quadrature points.
We first have to specify the form of the basis functions, then transform the basis functions to
the geometry of the element (which is irregular in the vertical because of the sigma
coordinate) and evaluate the basis function derivatives at the quadrature points.

Glissade uses trilinear basis functions defined on a reference cube.  
This cube is centered at the origin $(0,0,0)$ in local reference coordinates 
$(\hat{x}, \hat{y}, \hat{z}$). 
The eight nodes of the reference cube are located at $(\hat{x}, \hat{y}, \hat{z}) = (\pm 1, \pm 1, \pm 1)$.
By convention, nodes 1--4 are the nodes of the lower face, proceeding counterclockwise
from the southwest corner $(\hat{x}, \hat{y}) = (-1, -1)$. Nodes 5--8 are the nodes
of the upper face, also moving counterclockwise from the southwest corner.
Thus we have

\begin{equation}
  \label{gliss.eq.basis_functions}
  \begin{matrix}
    {{\varphi }_{1}}=(1-\hat{x})(1-\hat{y})(1-\hat{z})/8,  \\[3pt]
    {{\varphi }_{2}}=(1+\hat{x})(1-\hat{y})(1-\hat{z})/8,  \\[3pt]
    {{\varphi }_{3}}=(1+\hat{x})(1+\hat{y})(1-\hat{z})/8,  \\[3pt]
    {{\varphi }_{4}}=(1-\hat{x})(1+\hat{y})(1-\hat{z})/8,  \\[3pt]
    {{\varphi }_{5}}=(1-\hat{x})(1-\hat{y})(1+\hat{z})/8,  \\[3pt]
    {{\varphi }_{6}}=(1+\hat{x})(1-\hat{y})(1+\hat{z})/8,  \\[3pt]
    {{\varphi }_{7}}=(1+\hat{x})(1+\hat{y})(1+\hat{z})/8,  \\[3pt]
    {{\varphi }_{8}}=(1-\hat{x})(1+\hat{y})(1+\hat{z})/8.  \\
  \end{matrix}
\end{equation} 

\noindent
For each $n$ we have $\varphi_n = 1$ at a single node, with $\varphi_n = 0$ at the other nodes.

The integrands in \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv} 
are written in terms of real Cartesian coordinates $(x,y,z)$ rather than reference coordinates
$(\hat{x},\hat{y},\hat{z})$.
Spatial derivatives in real coordinates are related to derivatives in reference coordinates by

\begin{equation}
  \label{gliss.eq.real_to_reference}
  \scalebox{1.2}{
    $
  \left\{ \begin{matrix}
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{z}}  \\
  \end{matrix} \right\} = 
  \left[ \begin{matrix}
      \frac{\partial x}{\partial \hat{x}} & \frac{\partial y}{\partial \hat{x}} & \frac{\partial z}{\partial \hat{x}}  \\[6pt]
      \frac{\partial x}{\partial \hat{y}} & \frac{\partial y}{\partial \hat{y}} & \frac{\partial z}{\partial \hat{y}}  \\[6pt]
      \frac{\partial x}{\partial \hat{z}} & \frac{\partial y}{\partial \hat{z}} & \frac{\partial z}{\partial \hat{z}}  \\
    \end{matrix} \right]
  \left\{ \begin{matrix}
    \frac{\partial {{\varphi }_{n}}}{\partial x}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial y}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial z}  \\
  \end{matrix} \right\} =
   [J]\left\{ \begin{matrix}
     \frac{\partial {{\varphi }_{n}}}{\partial x}  \\[6pt]
     \frac{\partial {{\varphi }_{n}}}{\partial y}  \\[6pt]
     \frac{\partial {{\varphi }_{n}}}{\partial z}  \\
   \end{matrix} \right\},
   $
  }
\end{equation}

\noindent
where $[J]$ is the Jacobian of the transformation between coordinate systems.  
Given the finite-element expansion

\begin{equation}
   x = \sum\limits_{n}{{{\varphi }_{n}}{{x}_{n}}},
\end{equation}

\noindent
along with the spatial derivatives of $\varphi$ at $(\hat{x},\hat{y},\hat{z})$
(which are easily derived from \eqref{gliss.eq.basis_functions}),
we can compute $[J(\hat{x},\hat{y},\hat{z})]$ as

\begin{equation}
  \label{gliss.eq.Jacobian_eval}
  \scalebox{1.2}{
  $
        [J]=\left[ \begin{matrix}
            \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}{{x}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}{{y}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}{{z}_{n}}}  \\[6pt]
            \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}{{x}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}{{y}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}{{z}_{n}}}  \\[6pt]
            \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{z}}{{x}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{z}}{{y}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{z}}{{z}_{n}}}  \\
          \end{matrix} \right].
        $
        }
\end{equation}

\noindent
We then invert \eqref{gliss.eq.real_to_reference} to obtain the 
basis function derivatives in terms of $(x,y,z)$:

\begin{equation}
  \label{gliss.eq.reference_to_real}
  \scalebox{1.2}{
    $
  \left\{ \begin{matrix}
     \frac{\partial {{\varphi }_{n}}}{\partial x}  \\[6pt]
     \frac{\partial {{\varphi }_{n}}}{\partial y}  \\[6pt]
     \frac{\partial {{\varphi }_{n}}}{\partial z}  \\
  \end{matrix} \right\} =
          [J^{-1}]  \left\{ \begin{matrix}
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{z}}  \\
  \end{matrix} \right\}. 
          $
          }
\end{equation}

\noindent
The left-hand side of \eqref{gliss.eq.reference_to_real} contains the spatial derivatives 
appearing in \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv}.

Eqs. \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv} also contain the viscosity $\eta$,
which is computed at each quadrature point.
In the Blatter-Pattyn approximation, $\eta$ is given by \eqref{gliss.eq.effective_viscosity};
it is a function of the flow factor $A$ and the effective strain rate defined by \eqref{gliss.eq.effective_strain_rate}.
We approximate $A$ by its value at the element center.
The (squared) effective strain rate, ${{\dot{\varepsilon }}^{2}}_{e}$, is evaluated at each quadrature point
by summing over strain-rate components.  The $x$ components are given by

\begin{equation}
  \label{gliss.eq.strain_rates}
  \frac{\partial u}{\partial x}=\sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial x}}{{u}_{n}}, \quad
  \frac{\partial v}{\partial x}=\sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial x}}{{v}_{n}},
\end{equation}

\noindent
and similarly for the $y$ and $z$ components.  The nodal velocities in \eqref{gliss.eq.strain_rates}
are values from the previous iteration; otherwise the resulting system of equations would be nonlinear.

We now have the information needed to compute the integrands \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv}
at quadrature points. To integrate over a hexahedron, we take a weighted sum of the values at each
of eight quadrature points.  These points are located at
reference coordinates $(\hat{x},\hat{y},\hat{z}) = (\pm 1/\sqrt{3}, \pm 1/\sqrt{3}, \pm 1\sqrt{3})$.
To evaluate an integral of the form

\begin{equation}
  \int\limits_{\Omega }{\eta \left( \frac{\partial {{\varphi }_{i}}}{\partial z}\frac{\partial {{\varphi }_{j}}}{\partial z} \right)}d\Omega
\end{equation}

\noindent
over element volume $\Omega$, we compute the sum over quadrature points

\begin{equation}
  \label{gliss.eq.sum_over_qp}
  \sum\limits_{p=1}^{8}{{{w}_{p}}{{\eta }_{p}}{{\left( \frac{\partial {{\varphi }_{i}}}{\partial z}\frac{\partial {{\varphi }_{j}}}{\partial z} \right)}_{p}}}|J_p|,
\end{equation}

\noindent
where $|J|$ is the determinant of the Jacobian \eqref{gliss.eq.Jacobian_eval}. For this choice of quadrature points,
each point has $w_p = 1$.

The terms of the element matrices $\mathbf{K_{uu}}, \mathbf{K_{uv}}, \mathbf{K_{vu}}$ and $\mathbf{K_{vv}}$
are then inserted into the corresponding global matrices $\mathbf{A_{uu}}, \mathbf{A_{uv}}, \mathbf{A_{vu}}$ and $\mathbf{A_{vv}}$.
This is mostly a matter of bookkeeping.
For example, the first row of $\mathbf{K_{uu}}$ corresponds to a particular node of element $(k,i,j)$
(specifically, the node with indices $(k-1,i-1,j-1)$, given our convention for numbering nodes within elements).  
This row is mapped to a row of the global matrix $\mathbf{A_{uu}}$, 
and each of the eight terms in the row is associated with a column of $\mathbf{A_{uu}}$.  
Glissade determines the correct column
and adds the $\mathbf{K_{uu}}$ term to the corresponding term in $\mathbf{A_{uu}}$.  This process proceeds
until the code has looped over all the active elements and filled the global matrices.

If written in full, each global matrix would have as many rows and columns as there are active nodes.
These matrices, however, are sparse, with a maximum of 27 nonzero terms per row (corresponding to
a node and its 26 nearest neighbors in a 3D hexahedral lattice).
Glissade therefore assembles and stores global matrices of dimension $(27,nz,nx-1,ny-1)$.
The 27 terms of the first dimension are indexed such that each index has a geometric meaning.
Suppose we are filling columns for the matrix row corresponding to node $(k,i,j)$. 
Then, by convention, index 1 refers to the node with coordinates $(k-1,i-1,j-1)$, index 14 refers to the
node itself (i.e., the diagonal term of the row), and index 27 refers to the node at $(k+1,i+1,j+1)$
(and similarly for the other indices).
Ater assembly, these matrices can be converted as needed to the form required by a particular solver.

The remaining assembly consists of evaluating the other terms in \eqref{gliss.eq.weak_form}
(i.e., the basal and lateral boundary conditions and the gravitational forcing) and implementing
Dirichlet boundary conditions, if applicable. We consider these in turn.

\paragraph{Basal boundary conditions.}

At the basal boundary we assume a friction law of the form 

\begin{equation}
  \label{gliss.eq.beta_tau}
  \mathbf{\tau_b} = -\beta \mathbf{u_b}.  
\end{equation}

\noindent
The coefficient $\beta$ is defined at each vertex and can vary spatially.  
If $\beta$ depends on the velocity, as in some friction laws,
then it is calculated using the velocity from the previous iteration.
See Sections~\ref{sc:ho_basal_traction} and \ref{sc:ho_basal_yield}
for a detailed discussion of basal traction in higher-order models.

The basal boundary terms to be evaluated in \eqref{gliss.eq.weak_form} are

\begin{equation}
  \label{gliss.eq.basal_bc}
  \begin{split}
    x: \int\limits_{{\Gamma }_{B}} \beta u{{\varphi }_{1}} d\Gamma , \\
    y: \int\limits_{{\Gamma }_{B}} \beta v{{\varphi }_{2}} d\Gamma . \\
  \end{split}
\end{equation}

\noindent
The basal face of each cell is a rectangle. To integrate over a rectangle, we 
sum over terms at four quadrature points.  These points lie at $(\hat{x},\hat{y}) = (\pm 1/\sqrt{3}, \pm 1/\sqrt{3}$)
in a reference square with center $(0,0)$ and vertices $(\pm1,\pm1)$.
(This reference square is the 2D analog of the reference cube discussed above.)
We define four bilinear basis functions on the square (cf. \eqref{gliss.eq.basis_functions}):

\begin{equation}
  \label{gliss.eq.basis_functions_2d}
  \begin{matrix}
    {{\varphi }_{1}}=(1-\hat{x})(1-\hat{y})/4,  \\[3pt]
    {{\varphi }_{2}}=(1+\hat{x})(1-\hat{y})/4,  \\[3pt]
    {{\varphi }_{3}}=(1+\hat{x})(1+\hat{y})/4,  \\[3pt]
    {{\varphi }_{4}}=(1-\hat{x})(1+\hat{y})/4.
  \end{matrix}
\end{equation}

\noindent
Given these basis functions and their spatial derivatives, we can compute the Jacobian
for the transformation between the reference square and the rectangular cell face,
using the 2D versions of \eqref{gliss.eq.Jacobian_eval} and \eqref{gliss.eq.reference_to_real}:

\begin{equation}
  \label{gliss.eq.Jacobian_eval_2d}
  \scalebox{1.2}{
  $
        [J]=\left[ \begin{matrix}
            \sum\limits_{n=1}^{4}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}{{x}_{n}}} & \sum\limits_{n=1}^{4}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}{{y}_{n}}} \\[6pt]
            \sum\limits_{n=1}^{4}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}{{x}_{n}}} & \sum\limits_{n=1}^{4}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}{{y}_{n}}} \\[6pt]
          \end{matrix} \right],
        $
        }
\end{equation}

\begin{equation}
  \label{gliss.eq.reference_to_real_2d}
  \scalebox{1.2}{
    $
  \left\{ \begin{matrix}
     \frac{\partial {{\varphi }_{n}}}{\partial x}  \\[6pt]
     \frac{\partial {{\varphi }_{n}}}{\partial y}  \\
  \end{matrix} \right\} =
          [J^{-1}]  \left\{ \begin{matrix}
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}  \\
  \end{matrix} \right\}. 
          $
          }
\end{equation}

The integrand at a quadrature point has the form
\begin{equation}
  \label{gliss.eq.beta_integrand}
  \beta \varphi_i \varphi_j,
\end{equation}

\noindent
where the second $\varphi$ term arises from the finite-element expansion of $u$ at a quadrature point:

\begin{equation}
  u = \sum\limits_{n=1}^{4} {u_n \varphi_n}.
\end{equation}

\noindent
We determine $\beta$ at quadrature points from the values at cell vertices:

\begin{equation}
  \beta = \sum\limits_{n=1}^{4} {\beta_n \varphi_n}.
\end{equation}

\noindent
The integral of \eqref{gliss.eq.beta_integrand} over a cell is then computed as a sum over quadrature points:

\begin{equation}
  \label{gliss.eq.sum_over_qp_beta}
  \sum\limits_{p=1}^{4} {w_p \beta_p (\varphi_i \varphi_j)_p |J_p|},
\end{equation}

\noindent
where $w_p = 1$ for each point.  This procedure generates a 4\text{x}4 matrix
describing the connections between each node and its neighbors in the cell.
%This is a 2D analog of the element matrices discussed above.  
Since the $x$ term in \eqref{gliss.eq.basal_bc} 
contains $u$ but not $v$, and the $y$ term contains
$v$ but not $u$, we form 2D matrices $\mathbf{K_{uu}}$ and $\mathbf{K_{vv}}$, but not $\mathbf{K_{uv}}$ and $\mathbf{K_{vu}}$.
Each term of $\mathbf{K_{uu}}$ is then inserted into the global matrix $\mathbf{A_{uu}}$, and
similarly for $\mathbf{K_{vv}}$ and $\mathbf{A_{vv}}$.

This assembly procedure tends to smooth the $\beta$ field.  If it is necessary to resolve
sharp discontinuities in $\beta$, as in the stream test problem of Section~\ref{sc:stream_test},
Glissade allows an alternate assembly procedure in which the terms in a given row of the matrix
depend only on $\beta$ at the vertex associated with that particular row of the matrix.
See option \texttt{which\_ho\_assemble\_beta} in Section~{\ref{ug.sec.config}.

\paragraph{Lateral boundary conditions.}

The lateral boundary terms in \eqref{gliss.eq.weak_form} are

\begin{equation}
  \label{gliss.eq.lateral_bc}
  \begin{split}
    x: \int\limits_{{\Gamma }_{L}} {p n_1 {{\varphi }_{1}} \text{ d}\Gamma}, \\
    y: \int\limits_{{\Gamma }_{L}} {p n_2 {{\varphi }_{2}} \text{ d}\Gamma}.
  \end{split}
\end{equation}

\noindent
Since these terms are independent of $u$ and $v$, they contribute to the load vectors
$\mathbf{b_u}$ and $\mathbf{b_v}$ on the right-hand side of \eqref{gliss.eq.matrix}.
They are integrated over the lateral faces of floating cells that border the ocean.
(Grounded cells are assumed to have no lateral forcing.)

The lateral faces bordering the ocean are quadrilaterals that can be mapped to a reference square.
The integral over each face is found by summing over four quadrature points.
Basis functions are given by \eqref{gliss.eq.basis_functions_2d}, and
the Jacobian of the reference square is computed using \eqref{gliss.eq.Jacobian_eval_2d}.
We evaluate the ice thickness $H$ at each quadrature point using

\begin{equation}
  \label{gliss.eq.thickness_qp}
  H = \sum\limits_{n=1}^{4} {H_n \varphi_n},
\end{equation}

\noindent
where the $H_n$ are nodal values.
%(Each lateral face contains two pairs of nodes aligned in the vertical; aligned nodes
%have the same values for $H$ and $s$.) 
The integrands have the form $p_n \varphi$, where $p_n$ is the vertically averaged
net pressure normal to the ice edge.  
(We use the vertically averaged pressure to avoid dealing with vertical shear at the ice edge.)
The net pressure is equal to the pressure
directed outward from the ice toward the ocean by the weight of the ice, minus the (smaller)
pressure directed inward from the ocean to the ice by the hydrostatic water pressure.
The outward pressure is obtained by integrating $\rho_i g (s-z) dz$ from $s-H$ to $s$
and then dividing by $H$; it is given by 

\begin{equation}
  \label{gliss.eq.lateral_pout}
  p_{\text{out}} = \frac{\rho_i g H}{2}.
\end{equation}

\noindent
The inward pressure is found by integrating $(-\rho_w g z dz)$ from $s-H$ to 0
and then dividing by $H-s$; it is given by

\begin{equation}
  \label{gliss.eq.lateral_pin1}
  p_{\text{in}} = \frac{\rho_w g (s-H)^2}{2H}
\end{equation}

\noindent
Assuming hydrostatic balance, we have $s-H = (\rho_i/\rho_w)H$. Thus \eqref{gliss.eq.lateral_pin1} becomes

\begin{equation}
  \label{gliss.eq.lateral_pin2}
  p_{\text{in}} = \frac{\rho_i g H}{2} \frac{\rho_i}{\rho_w}
\end{equation}

\noindent
Combining \eqref{gliss.eq.lateral_pout} and \eqref{gliss.eq.lateral_pin2} gives

\begin{equation}
  \label{gliss.eq.lateral_pnet}
  p_{\text{net}} = \frac{\rho_i g H}{2} \left(1 - \frac{\rho_i}{\rho_w}\right),
\end{equation}

\noindent
directed from the ice to the ocean.  
The integral of the pressure terms over a lateral face is then found as a sum over quadrature points:

\begin{equation}
  \label{gliss.eq.sum_over_qp_lateral}
  \sum\limits_{p=1}^{4} {\pm w_p (p_\text{net})_p (\varphi_i)_p |J_p|},
\end{equation}

\noindent
where the sign depends on the orientation of the face.  The resulting pressure terms
are inserted into the load vector (either $\mathbf{b_u}$ or $\mathbf{b_v}$, depending on the orientation)
in the rows associated with each of the four nodes of the face.

\paragraph{Gravitational driving stress.}

The gravitational forcing terms in \eqref{gliss.eq.weak_form} are

\begin{equation}
  \label{gliss.eq.gravity_forcing}
  \begin{split}
    x: \int\limits_{\Omega } {\rho g\frac{\partial s}{\partial x}} {{\varphi }_{1}}\text{ d}\Omega, \\
    y: \int\limits_{\Omega } {\rho g\frac{\partial s}{\partial y}} {{\varphi }_{2}}\text{ d}\Omega. \\
  \end{split}
\end{equation}

\noindent
To compute these terms we evaluate $\frac{\partial s}{\partial x}$ and $\frac{\partial s}{\partial y}$
at each active vertex.  A standard centered approximation at vertex $(i,j)$ is

\begin{equation}
  \label{gliss.eq.dsdx_centered}
  \frac{\partial s}{\partial x}(i,j) = \frac{s(i+1,j+1)+s(i+1,j)-s(i,j+1)-s(i,j)}{2\Delta x},
\end{equation}

\noindent
and similarly for $\frac{\partial s}{\partial y}$. This approximation works
well when the ice geometry is fixed but can cause problems when the geometry is evolving.
These problems arise because checkerboard noise in $s$ (which is common on structured meshes
with the velocity at cell vertices) is invisible to the momentum balance; 
it is canceled out by the centered averaging in \eqref{gliss.eq.dsdx_centered}.
Checkerboard noise can therefore persist and grow.  To damp this noise, Glissade 
can use an upstream average:

\begin{equation}
  \label{gliss.eq.dsdx_upstream}
  \frac{\partial s}{\partial x}(i,j) = \frac{1.5 (s(i+1,j+1) - s(i,j+1)) - 0.5 (s(i+1,j+2) - s(i,j+2))}{\Delta x}.
\end{equation}

\noindent
Here, ``upstream'' means in the direction of increasing surface elevation. Both \eqref{gliss.eq.dsdx_centered}
and \eqref{gliss.eq.dsdx_upstream} are second-order accurate.  The default is \eqref{gliss.eq.dsdx_centered},
but \eqref{gliss.eq.dsdx_upstream} can be chosen by setting \texttt{which\_ho\_gradient = 1} 
in the config file (see Section~\ref{ug.sec.config}).

Eqs. \eqref{gliss.eq.dsdx_centered} and \eqref{gliss.eq.dsdx_upstream} are ambiguous at the ice margin,
where one or more of the four cells neighboring a vertex are ice-free. (Cells with very thin ice,
$H < \texttt{thklim}$, are considered ice-free by the velocity solver. CISM's default value is $\texttt{thklim} = 100 \textrm{ m}$,
which is appropriate for Glide, but Glissade is typically run with $\texttt{thklim} = 1 \textrm{ m}$.)
One option is to include all cells, including ice-free cells, in the gradient.
This generally works well for land-based ice but gives large gradients with excessive ice speeds
at floating shelf margins.  A second option is to include only ice-covered cells in the gradient.
For example, suppose cells $(i,j)$ and $(i,j+1)$ have ice, but cells $(1+1,j)$ and $(i+1,j+1)$ are
ice-free.  Then, lacking the required information to compute a gradient in the $x$ direction, 
we would set $\frac{\partial s}{\partial x} = 0$.  The $y$ gradient would be one-sided:
$\frac{\partial s}{\partial y} = (s(i,j+1)-s(i,j)) \slash \Delta y$.  
This option works well at shelf margins but tends to underestimate slopes at land margins.
A third option is to include in the gradient any neighbor cells that are either ice-covered
or land cells.  (Land cells are cells with bedrock topography above sea level, whether ice-covered
or ice-free.)  Since this option (\texttt{which\_ho\_gradient\_margin = 1})
works well for both land and shelf margins, it is the default. 
    
The integrals in \eqref{gliss.eq.gravity_forcing} are over 3D elements.
Hence we map each hexahedral element to a reference cube as described above. 
Given $\frac{\partial s}{\partial x}$ at the nodes of a cell,
the surface slope terms at quadrature points are

\begin{equation}
  \frac{\partial s}{\partial x} = \sum\limits_{n=1}^{8}{{{\varphi }_{n}}}{{\left( \frac{\partial s}{\partial x} \right)}_{n}}, \quad
  \frac{\partial s}{\partial y} = \sum\limits_{n=1}^{8}{{{\varphi }_{n}}}{{\left( \frac{\partial s}{\partial y} \right)}_{n}},
\end{equation}

\noindent
where the basis functions $\varphi$ are given by \eqref{gliss.eq.basis_functions}
and the spatial derivatives are derived from \eqref{gliss.eq.Jacobian_eval} and \eqref{gliss.eq.reference_to_real}.
The integral of $\rho g \frac{\partial s}{\partial x} \varphi$
over an element is evaluated as a sum over quadrature points:

\begin{equation}
  \label{gliss.eq.sum_over_qp_gravity}
  \sum\limits_{p=1}^{8} { w_p \rho g \left(\frac{\partial s}{\partial x}\right)_p (\varphi_i)_p |J_p|},
\end{equation}

\noindent
and similarly for the $\frac{\partial s}{\partial y}$ term.
Glissade inserts these terms into the load vectors $\mathbf{b_u}$ and $\mathbf{b_v}$.

\paragraph{Dirichlet boundary conditions.}

Once the matrix has been assembled, it may need to be adjusted for Dirichlet boundary conditions
(i.e., prescribed values of the velocity at certain nodes). The most common Dirichlet condition
is to set $u = v = 0$ at the bed to enforce a no-slip boundary condition.  (A no-slip condition
can also be enforced by setting the basal traction coefficient $\beta$
to a very large value, but formally this is not a Dirichlet condition.)  Also, it may be desirable to
set $u$ and $v$ to observed values at certain locations, as in the Ross Ice Shelf test case
(Section~\ref{sc:ross_test}).

Suppose that at node $(k,i,j)$ we have $u = u_c$ and $v = v_c$, where $u_c$ and $v_c$ are prescribed values.  
Let $nr$ be the row of $\mathbf{A_{uu}}$ associated with this node, and let $nc$ range over the
columns with nonzero entries in this row.
To enforce the Dirichlet condition, we set $\mathbf{A_{uu}}(nr,nc) = \mathbf{A_{vv}}(nr,nc) = 0$ for all
values of $nc$ except $nc = nr$ (the diagonal term); we set $\mathbf{A_{uu}}(nr,nr) = \mathbf{A_{vv}}(nr,nr) = 1$.
In addition, we set $\mathbf{A_{uv}}(nr,nc) = \mathbf{A_{vu}}(nr,nc) = 0$ for all $nc$, since these two matrices do not contain
any terms on the diagonal of the full global matrix (i.e., $\mathbf{A}$ in \eqref{gliss.eq.matrix_full}).
On the right-hand side, we set $\mathbf{b_u}(nr) = u_c$ and $\mathbf{b_v}(nr) = v_c$.  These operations
convert the matrix rows associated with node $(k,i,j)$ to the equations $1 \cdot u = u_c, 1 \cdot v = v_c$,
which clearly have the desired solutions $u_c$ and $v_c$.

A further step is needed to maintain matrix symmetry, as required
when using a preconditioned conjugate gradient solver.  Consider the term $\mathbf{A_{uu}}(nr,nc)$,
where $nc$ is a specific column associated with a neighboring node (say, node $(k+1,i+1,j+1))$.
We have already set $\mathbf{A_{uu}}(nr,nc) = 0$, so we need to set $\mathbf{A_{uu}}(nc,nr) = 0$ to maintain
symmetry. The Dirichlet condition is $u(nr) = u_c$. 
In the matrix-vector product, the product $\mathbf{A_{uu}}(nc,nr) u(nr) = \mathbf{A_{uu}}(nc,nr) u_c$
contributes to $\mathbf{b_u}(nc)$.  Thus we can replace $\mathbf{b_u}(nc)$ with 
$\mathbf{b_u}(nc) -  \mathbf{A_{uu}}(nc,nr) u_c$
and set $\mathbf{A_{uu}}(nc,nr) = 0$ without altering the problem.
We do this for all the terms in the columns associated with node $(k,i,j)$ (i.e., all the
terms multiplied by $u_c$ or $v_c$ in the matrix-vector product).
Thus, both the rows and the columns associated with node $(k,i,j)$ are filled with zeros,
except for the diagonal term, and the full global matrix remains symmetric.

\subsubsection{Solving the linear system}

Once the matrices and right-hand side vectors have been assembled, we solve the linear problem
\eqref{gliss.eq.matrix}.  Glissade supports three kinds of solvers:

\begin{itemize}
\item A native Fortran 90 preconditioned conjugate gradient (PCG) solver
\item Links to the Sparse Linear Algebra Package (SLAP), with options for 
the generalized minimum residual (GMRES) and biconjugate gradient methods
\item Links to Trilinos, with options for PCG and GMRES, preconditioned by
incomplete lower-upper (ILU) factorization or a multigrid method
\end{itemize}

We describe each solver in turn.

\paragraph{Preconditioned conjugate gradient solver.}

The native PCG solver works directly with the assembled matrices
$\mathbf{A_{uu}}$, $\mathbf{A_{uv}}$, $\mathbf{A_{vu}}$, and $\mathbf{A_{vv}}$, along with the right-hand side vectors
$\mathbf{b_u}$ and $\mathbf{b_v}$.  These matrices are passed to one of two PCG solvers:
a ``standard'' solver or a Chronopolous-Gear solver.  The standard method 
for solving $\mathbf{Ax} = \mathbf{b}$ can be summarized as follows:

\begin{itemize}

\item Let $x_0$ denote the initial guess for $x$ ($x_0 = 0$ if no guess is available);
$r = b - Ax$ is the residual vector; $d$ is a conjugate direction vector;
$M$ is a preconditioning matrix: $\alpha, \beta, \eta_0$, $\eta_1$ and $\eta_2$ are scalars;
$q$ and $z$ are work vectors; and $(r,z)$ is the dot product of two vectors.

\item $r_0 = b - A x_0$, $d_0 = 0$, $\eta_0 = 1$ 

\item Do until converged:
  \begin{itemize}
\renewcommand{\labelitemii}{$\star$}
  \item Solve $M z = r$ for $z$ (the preconditioning step)
  \item $\eta_1 = (r,z)$
  \item $\beta = \eta_1/\eta_0$
  \item $d = z + \beta d$
  \item $\eta_0 = \eta_1$
  \item $q = A d$
  \item $\eta_2 = (d,q)$
  \item $\alpha = \eta_1/\eta_2$
  \item $x = x + \alpha d$
  \item $r = r - \alpha q$ (or periodically, set $r = b - A x$ and check for convergence)
  \end{itemize}
\end{itemize}

\noindent
There are two dot products, one matrix-vector product, and one preconditioning step per iteration.
The convergence condition is $\sqrt{(r,r)}/\sqrt{(b,b)} < \epsilon$, where $\epsilon$ is a small tolerance
($10^{-8}$ by default).
The convergence check is done every five iterations, as a compromise
between the expense of an extra matrix-vector multiply and that of unnecessary iterations.

This solver works either in serial or in parallel.  If run in parallel, the dot products
require global sums, and a halo update for $d$ is needed once per iteration.
Halo updates in CISM operate on 2D arrays with horizontal indices $i$ and $j$ (or 3D/4D 
arrays with additional indices).  This is the main reason for
leaving the global matrices and vectors in standard Fortran arrays, instead of
converting to a sparse matrix storage format such as compressed row storage.
In array form, it is easy to do halo updates of vectors $u$, $v$, $r_u$, $r_v$, $d_u$, $d_v$, etc.

The PCG solver has two preconditioning options:

\begin{itemize}
\item Diagonal (also known as Jacoby) preconditioning, in which the preconditioning matrix $\mathbf{M}$ consists
of the diagonal terms of $\mathbf{A}$, so that $\mathbf{M}$ is trivial to invert.  Convergence with diagonal preconditioning 
can be slow.
\item Shallow-ice-based preconditioning.  In this case $\mathbf{M}$ includes only the terms in $\mathbf{A}$
that link a given node to itself and its immediate neighbors above and below. The matrix $\mathbf{M}$ is then
tridiagonal, as in the shallow-ice approximation, and can be inverted efficiently. This preconditioner
works well when the physics is dominated by vertical shear and the horizontal terms are small, but not
as well when membrane stresses are important. Since the preconditioner is local (it consists of
independent column solves), it scales well with an increasing number of processors.
\end{itemize}

\noindent
Other preconditioning options could be added in the future. 
If the existing options are inefficient for a given problem, it may be better to use Trilinos (see below).

For small problems on a modest number of processors, the dominant cost is the matrix-vector
multiply required during each iteration.  For large problems on many processors, however, the global sums become
increasingly expensive.  To reduce the cost of global sums, the standard PCG algorithm can be
replaced by the Chronopoulos-Gear algorithm, which rearranges operations such that both global sums
are done with a single MPI call.  We omit the details here, but refer the reader
to the code comments in module \texttt{glissade\_velo\_higher\_pcg.F90}. 

\paragraph{SLAP.}

The Sparse Linear Algebra Package (SLAP) is a set of Fortran routines for solving sparse systems of linear
equations. SLAP was part of the original Glimmer release and is still used to solve the thickness evolution
and temperature advection problems in Glide.  It can also be used to solve higher-order systems in Glissade,
using either GMRES or a biconjugate gradient solver.
SLAP, however, is limited to a single processor and thus is unsuited for large problems.

In order for Glissade to use CISM's SLAP routines, it must convert the global matrices and the 
right-hand-side and solution vectors to a SLAP-friendly format. First (before any matrix assembly),
Glissade assigns a unique integer ID to each active node.  Following assembly, the code loops through the matrices
$\mathbf{A_{uu}}$, $\mathbf{A_{uv}}$, $\mathbf{A_{vu}}$ and $\mathbf{A_{vv}}$, putting each nonzero entry into a Fortran derived type containing
the row, column and value of such entry.  Similarly, the current solution and the right-hand side are placed
in SLAP-friendly vectors. This information is passed to the SLAP solver
and ultimately to the various SLAP subroutines.  SLAP returns the velocity solution
and residual vectors, which are copied back into Glissade data structures.

\paragraph{Trilinos.}

\href{http://trilinos.org}{Trilinos} is a set of solver packages and related software developed at 
Sandia National Laboratories. Under the 
\href{http://www.csm.ornl.gov/ISICLES/}{DOE ISICLES project},
the Glam higher-order dycore was parallelized and linked to Trilinos.  The Trilinos links
developed for Glam were later adapted for Glissade.  Trilinos has been tested extensively on
parallel architectures and has been installed on DOE high-performance computers where 
CISM is often run.
See Section~\ref{sc:install_trilinos} for instructions on building CISM with Trilinos.

A C++ file, \texttt{libglimmer-trilinos/trilinosGlissadeSolver.cpp}, contains procedures that
link Glissade to Trilinos:

\begin{itemize}
\item \texttt{initializetgs} sends Trilinos a global ID for each active node.
\item \texttt{insertrowtgs} sends Trilinos a row of the matrix (specifically, the global row index, the number of
potentially nonzero column entries, the index and value of each such entry, and the associated right-hand side term).
\item \texttt{solvevelocitytgs} returns the velocity solution.
\end{itemize}

Various Glissade subroutines gather the information needed by Trilinos.  Before assembly, Glissade computes
global IDs for each node $(k,i,j)$ on each processor, along with unique indices for each unknown ($u$ and $v$)
on each active node.  Glissade also computes a logical array of dimension $(27,nz,nx-1,ny-1)$---the same dimension
as the global matrices---whose value is \texttt{.true.} for the potential nonzero entries.
After assembly of $\mathbf{A_{uu}}$, $\mathbf{b_u}$, etc., the nonzero matrix entries are passed to Trilinos, one row at a time.
After solution, the Trilinos velocity result is copied to Glissade data structures.

Trilinos solver options are set in a file called \texttt{trilinosOptions.xml} in the directory where the code
is executed.
Among the key settings are the solver type and preconditioner type.  The default solver is \texttt{Block GMRES},
and the default preconditioner is \texttt{Ifpack}, which applies ILU preconditioning.  ILU generally works well
for problems where shallow-ice physics is dominant, but can struggle for shelf-type problems where
membrane stresses are dominant.  For these problems the \texttt{ML} preconditioner type, which uses a multigrid
method for preconditioning, is likely to work better.  Optimal Trilinos settings for large, complex
problems are an area of active research.

Choosing among the various solver options is something of an art.  The default is native PCG using
the Chronopoulos-Gear algorithm.  The PCG solver runs efficiently on most platforms and scales well.
On the other hand, its preconditioning options are limited, so convergence may be slow for problems
with dominant membrane stresses.  SLAP solvers are generally robust and efficient, but are limited
to one processor.  Trilinos is typically slower than the other solvers, in part because of the
extra cost of setting up Trilinos data structures, as well as the slower performance of C++ code
relative to Fortran on many platforms.  On the other hand, Trilinos contains a vast range of
solver options (only a few of which have so far been tested with CISM), some of which may 
be more flexible and robust than those implemented in SLAP and the native PCG solver.

\subsubsection{Solving the nonlinear system}

Each call to a linear solver (native PCG, SLAP, or Trilinos) returns a solution vector,
along with the number of iterations and the error, defined as $\sqrt{(r,r)}/\sqrt{(b,b)}$.
If the linear solution fails to converge after the maximum allowed number of iterations
(typically 200), the solver exits with the last computed solution (which may be adequate
despite being unconverged).

Then a new global matrix is assembled, using the latest velocity solution to compute 
the effective viscosity.  The right-hand is adjusted as needed to incorporate Dirichlet
boundary conditions.  Glissade then computes the new residual $b - Ax$.  If the $L_2$ norm of the
residual (defined as $\sqrt{(r,r)}$) is smaller than a desired threshold ($10^{-4}$ by default),
the nonlinear system of equations is considered solved.
(An absolute threshold of $10^{-4}$ may be too stringent for large problems.  Alternatively,
Glissade can use a relative threshold, based on the ratio of the L2 norm of the residual to the L2 norm of
$\mathbf{b}$; see Section~\ref{ug.sec.config}.)
Otherwise the linear solver is called again, until either the solution converges or the 
maximum number of nonlinear iterations (typically 100) is reached.

As mentioned above, the procedure of updating the matrix with the latest guess for the solution
is known as Picard iteration.  The older Glam dycore includes an option
to solve the nonlinear system using a Jacobian-Free Newton-Krylov (JFNK) method.
JFNK requires an extra residual evaluation per nonlinear iteration, but generally
converges in fewer iterations than does the Picard method.  Glissade does not yet
have a JFNK option.

In addition to the 3D Blatter-Pattyn approximation, Glissade can solve the simpler shallow-ice
and shallow-shelf approximations, as well as the vertically integrated, higher-order ``L1L2''
approximation \citep{Schoof:2010dl}.  These are described next.

\subsection{Shallow-ice approximation}
\label{sc:glissade-sia}

\subsubsection{SIA: matrix form}

By setting \texttt{which\_ho\_approx = 0} in the config file, Glissade's finite-element solver can be used as an
SIA solver. The shallow-ice equations follow from the Blatter-Pattyn equations if the horizontal-stress
terms are neglected.  The SIA analogs of \eqref{gliss.eq.stress_balance} are

\begin{equation}
  \label{gliss.eq.stress_balance_sia}
  \begin{split}
    x: \frac{\partial }{\partial z}\left( \eta \frac{\partial u}{\partial z} \right) = \rho g\frac{\partial s}{\partial x}, \\
    y: \frac{\partial }{\partial z}\left( \eta \frac{\partial v}{\partial z} \right) = \rho g\frac{\partial s}{\partial y}, \\
  \end{split}
\end{equation}

\noindent
leading to the following internal stress terms in weak form:

\begin{equation}
  \label{gliss.eq.element_matrix_sia}
  \begin{split}
    x: \int\limits_{\Omega } {2 \eta \frac{\partial {{\varphi }_{i}}}{\partial z}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial z} \right]\left\{ {{u}_{j}} \right\} \right) },  \\
    y: \int\limits_{\Omega } {2 \eta \frac{\partial {{\varphi }_{i}}}{\partial z}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial z} \right]\left\{ {{v}_{j}} \right\} \right) }.  \\
  \end{split}
\end{equation}

\noindent
These terms are integrated over elements using \eqref{gliss.eq.basis_functions}
and \eqref{gliss.eq.Jacobian_eval} for the 3D basis functions and Jacobians.
The resulting $8\text{x}8$ element matrices $\mathbf{K_{uu}}$ and $\mathbf{K_{vv}}$ link each node
to the eight nodes of the element, including itself.  Since there are no
horizontal stress terms, $\mathbf{K_{uv}}$ = $\mathbf{K_{vu}}$ = 0. In the expression for
effective viscosity, the effective strain rate is given by

\begin{equation}
  \label{gliss.eq.effective_strain_rate_sia}
        {\dot{\varepsilon }}^{2}_{e} = {\dot{\varepsilon }}^{2}_{xz} + {\dot{\varepsilon }}^{2}_{yz}.
\end{equation}

\noindent
The basal and lateral boundary conditions and gravitational loading are handled
just as for the Blatter-Pattyn case.

The resulting SIA global matrices contain about half as many nonzero terms as the BP matrices,
since $\mathbf{A_{uv}}$ = $\mathbf{A_{vu}}$ = 0.  Each ice column, however, cannot be solved independently of the others;
rather, each node is linked to its horizontal neighbors by terms that arise during
element assembly.  As a result, the matrix-based SIA solver is not dramatically faster than the BP solver.
This solver can be useful for code testing
but is not practical for productions runs, since a practical SIA solver should be many times
faster than a BP solver.  Glissade has a much faster alternative SIA solver,
described next.

\subsubsection{SIA: Local form}

Glissade's local shallow-ice solver (in \texttt{glissade\_velo\_sia.F90}),
is distinct from the finite-element solvers described in this section.
It is local in the sense that $u$ and $v$ in each ice column are found independently
of $u$ and $v$ in all other columns.
It resembles the Glide shallow-ice solver described in Section \ref{sc:glide_thickness_evolution}.
Glide, however, incorporates the velocity solution in a diffusion equation for ice thickness.
Glissade's local SIA solver computes $u$ and $v$ only, with
thickness evolving separately as described in Section \ref{sc:glissade-transport}.

The local SIA solver first computes the basal velocity given the basal traction coefficient $t_b$,
which is defined as in Glide:

\begin{equation}
  \mathbf{u_b} = t_b \mathbf{\tau_b}.
\end{equation}

\noindent
Note that $t_b = 1/\beta$, where the higher-order traction coefficient $\beta$ 
is defined as in \eqref{gliss.eq.beta_tau}.
There are several options for setting $t_b$: no sliding ($t_b = 0$);
uniform traction ($t_b = \mathrm{constant}$); uniform traction where basal water is present
(and no sliding elsewhere); and uniform traction where the bed is at the pressure melting point,
$T_b = T_{pmp}$ (and no sliding elsewhere).
As in Glide, the basal velocity is proportional to $t_b$ and the gravitational driving stress:

\begin{equation}
  \label{gliss.eq.velo_bed_sia}
        \mathbf{u_b} = -{{t}_{b}}{{\rho }_{i}} g \bar{H} \nabla s,
\end{equation}

\noindent
where $\bar{H}$ is the ice thickness interpolated to cell vertices
and $\nabla s$ is the surface slope at vertices.

To find the interior velocities, we
first compute a vertically integrated factor $c(\sigma)$ for each level at each cell vertex:

\begin{equation}
  \label{gliss.eq.vert_factor_sia}
  c(\sigma) = -2(\rho g)^n \bar{H}^{n+1} |\vec\nabla s|^{n-1} \int_1^{\sigma} \bar{A} \tilde{\sigma}^n d\tilde{\sigma},
\end{equation}

\noindent
where $\bar{A}$ is the flow factor interpolated to vertices,
and a tilde distinguishes $\sigma$ at a particular level from the integration variable $\tilde{\sigma}$.
(The same term appears in the Glide SIA calculation; see \eqref{kin.eq.horiz_diffusivity}.)
Discretized in the vertical, this becomes

\begin{equation}
  \label{gliss.eq.vert_factor_sia_discrete}
  c(k) = -2(\rho g)^n \bar{H}^{n+1} |\vec\nabla s|^{n-1} 
  \sum\limits_{l=nz-1}^{k} {{{{\bar{A}}}_{l}}}{{\left( \frac{{{\sigma }_{l}}+{{\sigma }_{l+1}}}{2} \right)}^{n}}\left( 
               {{\sigma }_{l+1}}-{{\sigma }_{l}} \right).
\end{equation}

\noindent
The factors $c(k)$ are interpolated from cell vertices to edges.  The $u$ and $v$ 
components of velocity are computed at cell edges as a function of the surface slope: 

\begin{equation}
  \label{gliss.eq.velo_interior_sia}
  \begin{split}
    {\Delta {u}_{E}}(k,i,j) = \sum\limits_{l=nz-1}^{k}{\left( \frac{c(k,i,j)+c(k,i,j-1)}{2} \right)\left( s(i+1,j)-s(i,j) \right)}, \\
    {\Delta {v}_{N}}(k,i,j) = \sum\limits_{l=nz-1}^{k}{\left( \frac{c(k,i,j)+c(k,i-1,j)}{2} \right)\left( s(i,j+1)-s(i,j) \right)}.
  \end{split}
\end{equation}

\noindent
Here, $\Delta{u_E}$ is the $u$ velocity component on the east edge of a cell, relative to the basal velocity,
and similarly for $\Delta{v_N}$ on the north edge of the cell.

Finally, we average $\Delta u_E$ and $\Delta v_N$ to vertices and add the bed velocities 
\eqref{gliss.eq.velo_bed_sia} to determine the velocity in the ice column at each vertex:

\begin{equation}
  \label{gliss.eq.velo_sia}
  \begin{split}
    u(k,i,j) = u_b(i,j) + \left( \frac{\Delta {{u}_{E}}(k,i,j) + \Delta {{u}_{E}}(k,i,j+1)}{2} \right), \\
    v(k,i,j) = v_b(i,j) + \left( \frac{\Delta {{v}_{N}}(k,i,j) + \Delta {{v}_{N}}(k,i+1,j)}{2} \right).
  \end{split}
\end{equation}

For serial problems there are no special advantages to using Glissade's local SIA solver 
in place of Glide.  Glissade's local SIA solver, however, can run on multiple processors, 
whereas Glide cannot.  For large SIA problems, parallel Glissade can hold more data
in memory and may be faster.

\subsection{Shallow-shelf approximation}

Glissade's finite-element solver can also be used as a shallow-shelf solver.  The SSA equations 
can be derived by vertically integrating the 3D Blatter-Pattyn equations.
They are valid when the basal shear stress is small or zero and the velocity is 
(to a good approximation) vertically uniform.  The shallow-shelf analog of \eqref{gliss.eq.stress_balance} is

\begin{equation}
  \label{gliss.eq.stress_balance_ssa}
  \begin{split}
    x: \quad \frac{\partial }{\partial x}\left( 2 \bar{\eta} H \left(2\frac{\partial u}{\partial x} +  \bar{\eta} H \frac{\partial v}{\partial y} \right) \right) 
    + \frac{\partial }{\partial y}\left( \bar{\eta} H \left( \frac{\partial u}{\partial y} + \frac{\partial v}{\partial x} \right) \right) 
    = \rho g\frac{\partial s}{\partial x}, \\
    y: \quad \frac{\partial }{\partial y}\left( 2 \bar{\eta} H \left( 2\frac{\partial v}{\partial y} + \bar{\eta} H \frac{\partial u}{\partial x} \right) \right) 
    + \frac{\partial }{\partial x}\left( \bar{\eta} H \left( \frac{\partial u}{\partial y} + \frac{\partial v}{\partial x} \right) \right) 
    = \rho g\frac{\partial s}{\partial y},  \\
  \end{split}
\end{equation}

\noindent
where $\bar{\eta}$ is the vertically averaged effective viscosity.
The SSA equations in weak form resemble \eqref{gliss.eq.weak_form},
but with internal stress terms

\begin{equation}
  \label{gliss.eq.element_matrix_ssa}
  \begin{split}
    x: \int\limits_{\Omega }{2\bar{\eta} H \left( \frac{\partial {{\varphi }_{i}}}{\partial x}\left( 2\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{u}_{j}} \right\} + \left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{v}_{j}} \right\} \right) +
      \frac{\partial {{\varphi }_{i}}}{\partial y}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{u}_{j}} \right\}+\frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{v}_{j}} \right\} \right) \right)},  \\
    y: \int\limits_{\Omega }{2\bar{\eta} H \left( \frac{\partial {{\varphi }_{i}}}{\partial y}\left( 2\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{v}_{j}} \right\} + \left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{u}_{j}} \right\} \right) + 
      \frac{\partial {{\varphi }_{i}}}{\partial x}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{v}_{j}} \right\}+\frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{u}_{j}} \right\} \right) \right)}.  \\
  \end{split}
\end{equation}

\noindent
The resulting element matrices are similar to \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv},
except that the terms containing $\frac{\partial {{\varphi }_{i}}}{\partial z}$ and
$\frac{\partial {{\varphi }_{j}}}{\partial z}$ are missing, and the viscosity term $\eta$
is replaced by $\bar{\eta} H$.  The effective viscosity is defined as in \eqref{gliss.eq.effective_viscosity},
but with a vertically averaged flow factor and with \eqref{gliss.eq.effective_strain_rate} replaced by

\begin{equation}
  \label{gliss.eq.effective_strain_rate_ssa}
        {{\dot{\varepsilon }}^{2}}_{e} = 
        {{\dot{\varepsilon }}^{2}}_{xx} + {{\dot{\varepsilon }}^{2}}_{yy} + 
        {{\dot{\varepsilon }}_{xx}}{{\dot{\varepsilon }}_{yy}} + {{\dot{\varepsilon }}^{2}}_{xy}.
\end{equation}

\noindent
The integrals in \eqref{gliss.eq.element_matrix_ssa} are taken over 2D cells rather than 3D elements,
with basis functions and Jacobians given by \eqref{gliss.eq.basis_functions_2d}
and \eqref{gliss.eq.Jacobian_eval_2d}.

The basal boundary terms are handled as in the 3D Blatter-Pattyn approximation. 
The lateral boundary and gravitational forcing terms are computed initially in 3D
(as for the Blatter-Pattyn case), but then are summed in the vertical before being
inserted into the 2D right-hand vectors $\mathbf{b_u}$ and $\mathbf{b_v}$.  The solution procedure
is the same as for the 3D case, except that the problem has no vertical dimension.
When using the native PCG solver, the shallow-ice-based preconditioner is inappropriate
and the diagonal preconditioner should be used instead.  

In short, the SSA problem is similar to the Blatter-Pattyn problem except for the
missing vertical shear terms and the reduction to 2D.  The solution is much faster, because the SSA matrices
have roughly $3*nz$ times fewer nonzero entries than the Blatter-Pattyn matrices.
The factor of 3 arises from the fact that the BP equations at each level include
connections to the levels above and below, whereas the SSA equations
are solved at a single level.

\subsection{L1L2 approximation}

The L1L2 approximation \citep{Schoof:2010dl} can be derived by vertically integrating
the Blatter-Pattyn equations with the assumption that the horizontal gradients of the membrane
stresses are uniform with depth.
(The term ``L1L2'' is based on the classification scheme of \citet{Hindmarsh2004}.)  
This assumption leads to a 2D matrix system (like the SSA), which can be solved
much more cheaply than the 3D BP system.
The L1L2 approximation is about as accurate as the BP equations in
regions of fast sliding.  In regions of little or no sliding, it reduces to the
shallow-ice approximation.  Thus it is accurate where the SIA is accurate,
but not in regions of slow sliding and rough bed topography, where
the horizontal gradients of the membrane stresses vary strongly with height.
For example, L1L2 performs poorly for ISMIP-HOM Test A.

Consider the Blatter-Pattyn equations \eqref{gliss.eq.stress_balance}, written in
terms of deviatoric stresses instead of strain rates:

\begin{equation}
  \label{gliss.eq.stress_balance_tau}
  \begin{split}
    x: \quad \frac{\partial }{\partial x}\left( 2 \tau_{xx} + \tau_{yy} \right)
           + \frac{\partial }{\partial y}\left( \tau_{xy} \right)
           + \frac{\partial }{\partial z}\left( \tau_{xz} \right)
           = \rho g\frac{\partial s}{\partial x}, \\
    y: \quad \frac{\partial }{\partial y}\left( 2 \tau_{yy} + \tau_{xx} \right)
           + \frac{\partial }{\partial x}\left( \tau_{xy} \right)
           + \frac{\partial }{\partial z}\left( \tau_{yz} \right)
           = \rho g\frac{\partial s}{\partial y}.
  \end{split}
\end{equation}

\noindent
Assuming that $\tau_{xx}$, $\tau_{yy}$ and $\tau_{xy}$ are depth-independent,
\eqref{gliss.eq.stress_balance_tau} can be integrated from $b$ to $s$ to obtain

\begin{equation}
  \label{gliss.eq.stress_balance_tau_integrated}
  \begin{split}
    x: \quad \frac{\partial }{\partial x} \left( \int_b^s (2 \tau_{xx} + \tau_{yy}) dz \right)
           + \frac{\partial }{\partial y} \left( \int_b^s {\tau_{xy} dz} \right)
           - \beta u_b = \rho g H \frac{\partial s}{\partial x}, \\
    y: \quad \frac{\partial }{\partial y} \left( \int_b^s (2 \tau_{yy} + \tau_{xx}) dz \right)
           + \frac{\partial }{\partial x} \left( \int_b^s {\tau_{xy} dz} \right)
           - \beta v_b = \rho g H \frac{\partial s}{\partial y},
  \end{split}
\end{equation}

\noindent
where $u_b$ and $v_b$ are the components of basal velocity, and we have used
\href{http://en.wikipedia.org/wiki/Leibniz_integral_rule}{Leibniz's rule}
to move the partial derivatives outside the integrals and eliminate several boundary terms.
Sinc the deviatoric stresses are depth-independent, they can be written in terms of the
basal strain rates. Taking these strain rates outside the integral, we obtain

\begin{equation}
  \label{gliss.eq.stress_balance_tau_integrated}
  \begin{split}
    x: \quad 2 \frac{\partial }{\partial x} \left( \bar{\eta}H \left( 2 \frac{\partial u_b}{\partial x} + \frac{\partial v_b}{\partial y} \right) \right)
             + \frac{\partial }{\partial y} \left( \bar{\eta}H \left(   \frac{\partial u_b}{\partial y} + \frac{\partial v_b}{\partial x} \right) \right)
             - \beta u_b = \rho g H \frac{\partial s}{\partial x}, \\
    y: \quad 2 \frac{\partial }{\partial y} \left( \bar{\eta}H \left( 2 \frac{\partial v_b}{\partial y} + \frac{\partial u_b}{\partial x} \right) \right)
             + \frac{\partial }{\partial x} \left( \bar{\eta}H \left(   \frac{\partial u_b}{\partial y} + \frac{\partial v_b}{\partial x} \right) \right)
             - \beta v_b = \rho g H \frac{\partial s}{\partial y}, \\
  \end{split}
\end{equation}

\noindent
where the vertically averaged effective viscosity is

\begin{equation}
  \bar{\eta} = \int_b^s {\eta dz}.
\end{equation}

\noindent
Note the similarity between \eqref{gliss.eq.stress_balance_tau_integrated} and \eqref{gliss.eq.stress_balance_ssa}.
When \eqref{gliss.eq.stress_balance_ssa} is vertically integrated and basal boundary terms are included,
it is formally identical to \eqref{gliss.eq.stress_balance_tau_integrated}.  Thus the same methods used to
assemble and solve the SSA equations can be applied to the L1L2 equations.

The effective viscosity, however, is treated differently for L1L2.
(Here we follow \citet{Perego2012}.)
The parallel norm $\left| \cdot \right|_{||}$ is defined as

\begin{equation}
  \label{gliss.eq.L1L2_parallel_norm}
  \left| {\dot{\varepsilon }} \right|_{\parallel}^{2} = 
  \dot{\varepsilon }_{xx}^{2} + \dot{\varepsilon }_{yy}^{2} + {{\dot{\varepsilon }}_{xx}}{{\dot{\varepsilon }}_{yy}} + \dot{\varepsilon }_{xy}^{2}
\end{equation}

\noindent
and the perpendicular norm $\left| \cdot \right|_{\perp}$ as

\begin{equation}
  \label{gliss.eq.L1L2_perp_norm}
  \left| {\dot{\varepsilon }} \right|_{\perp}^{2} = 
  \dot{\varepsilon }_{xz}^{2} + \dot{\varepsilon }_{yz}^{2}.
\end{equation}

\noindent
The constitutive law can be written as 

\begin{equation}
  \label{gliss.eq.L1L2_constitutive}
  {{\dot{\varepsilon }}_{ij}} = A \tau _{e}^{2} {{\tau }_{ij}},
\end{equation}

\noindent
where we assume $n=3$.  For the L1L2 approximation the effective stress is given by

\begin{equation}
  \label{gliss.eq.L1L2_tau_effective}
  \tau _{e}^{2} = \left| \tau  \right|_{\parallel }^{2} + \tilde{\tau}_{\perp}^2,
\end{equation}

\noindent
with $\tilde{\tau}_{\perp}$ estimated based on the SIA:

\begin{equation}
  \label{gliss.eq.L1L2_tau_perp}
  \tilde{\tau}_{\perp}^{2} = {\left[ \rho g(s-z)\nabla s \right]}^2.
\end{equation}

\noindent
Inserting \eqref{gliss.eq.L1L2_tau_effective} in \eqref{gliss.eq.L1L2_constitutive} and taking 
the parallel norm gives

\begin{equation}
  \label{gliss.eq.L1L2_tau_parallel}
        {\left| {\dot{\varepsilon }} \right|}_{\parallel}
        = A (\left| \tau \right|_{\parallel}^{2} + \left| \tau \right|_{\perp}^{2}) {{\left| \tau \right|}_{\parallel}}.
\end{equation}

\noindent
Given ${\left| {\dot{\varepsilon }} \right|}_{\parallel}$ from \eqref{gliss.eq.L1L2_parallel_norm},
equation \eqref{gliss.eq.L1L2_tau_parallel} can be written in the form $x^3 + a x + b = 0$,
a cubic equation that can be solved for ${\left| \tau \right|}_{\parallel}$ using standard techniques.
(Of the three roots, the one of interest is real and positive; the other two are complex conjugates.
Glissade currently computes ${\left| \tau \right|}_{\parallel}$ only for $n = 3$,
although an iterative scheme for general $n$ could be added later.)
The effective viscosity at depth $z$ is then given by

\begin{equation}
  \label{gliss.eq.L1L2_eta}
  \eta  = \frac{1}{2A \tau_{e}^{2}},
\end{equation}

\noindent
where $\tau_{e}$ is obtained from \eqref{gliss.eq.L1L2_tau_effective},
\eqref{gliss.eq.L1L2_tau_perp} and \eqref{gliss.eq.L1L2_tau_parallel}.
Equation \eqref{gliss.eq.L1L2_eta} follows from \eqref{gliss.eq.L1L2_constitutive}
and the relation 
\begin{equation}
  \label{gliss.eq.L1L2_eta2}
  {\tau_{ij}} = 2\eta {\dot{\varepsilon}_{ij}},
\end{equation} 
which defines the effective viscosity.

After solving the 2D L1L2 system for the basal velocity, the velocity profile at each vertex
can be found by vertical integration. First we estimate
$\tau_{xz}$ and $\tau_{yz}$ in each layer.  Since the depth-independent membrane stresses
are determined by the basal velocity, $\tau_{xz}$ and $\tau_{yz}$ are now the
only unknowns in \eqref{gliss.eq.stress_balance_tau}.  These equations can be integrated
from the top surface (assumed to be stress-free) to depth $z$ to give

\begin{equation}
  \begin{split}
    x: \quad {{\tau }_{xz}}(z) = -\rho g(s-z)\frac{\partial s}{\partial x} 
    + 2\frac{\partial }{\partial x}\left[ \left( 2\frac{\partial {{u}_{b}}}{\partial x}+\frac{\partial {{v}_{b}}}{\partial y} \right)
      \left( \int\limits_{z}^{h}{\eta d{z}'} \right) \right] 
    + 2\frac{\partial }{\partial y}\left[ \left(  \frac{\partial {{u}_{b}}}{\partial y}+\frac{\partial {{v}_{b}}}{\partial x} \right)
      \left( \int\limits_{z}^{h}{\eta d{z}'} \right) \right], \\
    y: \quad {{\tau }_{yz}}(z) = -\rho g(s-z)\frac{\partial s}{\partial y} 
    + 2\frac{\partial }{\partial y}\left[ \left( 2\frac{\partial {{v}_{b}}}{\partial y}+\frac{\partial {{u}_{b}}}{\partial x} \right)
      \left( \int\limits_{z}^{h}{\eta d{z}'} \right) \right] 
    + 2\frac{\partial }{\partial x}\left[ \left(  \frac{\partial {{u}_{b}}}{\partial y}+\frac{\partial {{v}_{b}}}{\partial x} \right)
      \left( \int\limits_{z}^{h}{\eta d{z}'} \right) \right],
  \end{split}
\end{equation}

\noindent
where again we use Leibniz's rule to move the partial derivatives outside the integrals
and remove boundary terms.
The bracketed terms are evaluated at cell centers, and then the gradient terms are 
computed at nodes using finite-difference formulas (e.g., \eqref{gliss.eq.dsdx_centered}).
Given $\tau_{xz}$ and $\tau_{yz}$ at each level, along with
$\left| \dot{\varepsilon } \right|_{\parallel }^{2}$ from \eqref{gliss.eq.L1L2_parallel_norm},
the effective stress is given by

\begin{equation}
  \tau_{e}^{2} = 2 \eta \left| {\dot{\varepsilon }} \right|_{\parallel }^{2} + \tau_{xz}^{2} + \tau_{yz}^{2}.
\end{equation}

\noindent
The velocity components can then be integrated upward from the bed using

\begin{equation}
  \begin{split}
    x: \quad \frac{1}{2}\frac{\partial u}{\partial z} = {{\dot{\varepsilon }}_{xz}} = A\tau _{e}^{n-1}{{\tau }_{xz}}, \\
    y: \quad \frac{1}{2}\frac{\partial v}{\partial z} = {{\dot{\varepsilon }}_{yz}} = A\tau _{e}^{n-1}{{\tau }_{yz}},
  \end{split}
\end{equation}

\noindent
which imply

\begin{equation}
  \begin{split}
    \label{gliss.eq.L1L2_velo3d}
    x: \quad u(z) = {{u}_{b}} + 2\int\limits_{b}^{z}{A\tau_{e}^{n-1}}{{\tau }_{xz}}dz, \\
    y: \quad v(z) = {{v}_{b}} + 2\int\limits_{b}^{z}{A\tau_{e}^{n-1}}{{\tau }_{yz}}dz.
  \end{split}
\end{equation}

