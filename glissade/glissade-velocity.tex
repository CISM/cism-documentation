
\section{Velocity solver}
\label{sc:glissade-velocity}

Glissade computes the ice velocity by solving an appropriate
approximation of the Stokes equations, given the 2D surface elevation and thickness fields,
the 3D temperature field, and relevant boundary conditions.
Section \ref{sc:glissade-blatter-pattyn} describes assembly and solution of the matrix problem for the 
3D first-order Blatter-Pattyn approximation.  
Section \ref{sc:glissade-other-approx} discusses simpler approximations, including the SIA and SSA.

\subsection{Blatter-Pattyn approximation}
\label{sc:glissade-blatter-pattyn}

The basic equations of the Blatter-Pattyn approximation in Cartesian coordinates, repeated from 
Section \ref{sc:higher-order-mom}, are 

\begin{equation}
  \label{gliss.eq.stress_balance}
  \begin{split}
    x: \quad \frac{\partial }{\partial x}\left( 2 \eta \left(2\frac{\partial u}{\partial x} +  \eta \frac{\partial v}{\partial y} \right) \right) 
    + \frac{\partial }{\partial y}\left[ \eta \left( \frac{\partial u}{\partial y} + \frac{\partial v}{\partial x} \right) \right] 
    +\frac{\partial }{\partial z}\left( \eta \frac{\partial u}{\partial z} \right) = \rho g\frac{\partial s}{\partial x}, \\
    y: \quad \frac{\partial }{\partial y}\left( 2 \eta \left( 2\frac{\partial v}{\partial y} + \eta \frac{\partial u}{\partial x} \right) \right) 
    + \frac{\partial }{\partial x}\left[ \eta \left( \frac{\partial u}{\partial y} + \frac{\partial v}{\partial x} \right) \right] 
    +\frac{\partial }{\partial z}\left( \eta \frac{\partial v}{\partial z} \right) = \rho g\frac{\partial s}{\partial y},  \\
  \end{split}
\end{equation}

\noindent
where $u$ and $v$ are the components of horizontal velocity, $\eta$ is the effective viscosity, $s$ is the ice surface elevation,
$\rho$ is the density of ice (assumed constant), and $g$ is gravitational acceleration.  

As in Glide, the equations are discretized on a structured, rectangular horizontal mesh
of dimension $(nx,ny)$, together with a staggered mesh of dimension $(nx-1,ny-1)$.  The rectangles on the unstaggered mesh
are called \textit{cells}, and the corners of each cell (where four rectangles meet) are called \textit{vertices}.
The vertical \textit{levels} of the mesh are based on a terrain-following sigma coordinate system; 
we define $\sigma = (s-z)/H$, where $H$ is the ice thickness. Thus $\sigma = 0$ at the top surface and $\sigma = 1$ at the bed. 
There are $nz$ levels in the vertical direction, with $nz-1$ \textit{layers} between these levels.
An \textit{element} is the region associated with a particular cell and layer; there are
$(nx)(ny)(nz-1)$ elements on the mesh.  A \textit{node} is a point where eight elements intersect (or where four elements
intersect at the upper or lower surface). There are $(nx-1)(ny-1)(nz)$ nodes on the mesh.

Scalar 2D fields such as ice thickness $H$ and surface elevation $s$ are defined for each cell.
Scalar 3D fields such as ice temperature $T$ lie at the center of each element (i.e., at the midpoint of each layer
associated with  each cell). Gradients of 2D scalar fields (e.g., the surface slope $\nabla s$) are defined at vertices.
The velocity components $u$ and $v$ live at nodes.

An \textit{active cell} is a cell whose ice thickness exceeds a minimum threshold.  Each active cell is associated with
a column of $nz-1$ active elements.  An \textit{active vertex} is any vertex of an active cell.  Each active vertex is
associated with $nz$ active nodes, including nodes at the surface and bed.

The effective viscosity is defined in each active element by

\begin{equation}
  \label{gliss.eq.effective_viscosity}
  \eta \equiv \frac{1}{2} A^{\frac{-1}{n}} \dot{\varepsilon }_{e}^{\frac{1-n}{n}},
\end{equation}

\noindent
where $A$ is the temperature-dependent rate factor in Glen's flow law, and $\dot{\varepsilon }_{e}$ is the effective strain rate,
given in the Blatter-Pattyn approximation by 

\begin{equation}
  \label{gliss.eq.effective_strain_rate}
        {{\dot{\varepsilon }}^{2}}_{e}={{\dot{\varepsilon }}^{2}}_{xx}+{{\dot{\varepsilon }}^{2}}_{yy}+{{\dot{\varepsilon }}_{xx}}{{\dot{\varepsilon }}_{yy}}+{{\dot{\varepsilon }}^{2}}_{xy}+{{\dot{\varepsilon }}^{2}}_{xz}+{{\dot{\varepsilon }}^{2}}_{yz},
\end{equation}

\noindent
where

\begin{equation}
  \dot{\varepsilon }_{ij} = \frac{1}{2}\left( \frac{\partial u_{i}}{\partial x_{j}} + \frac{\partial u_{j}}{\partial x_{i}} \right).
\end{equation}

\noindent

Given $T$, $s$, $H$, and an initial guess for $u$ and $v$, the problem is to solve Eq. \eqref{gliss.eq.stress_balance}
for $u$ and $v$ at each active node.  (At inactive nodes we set $u=v=0$.)  This problem can be written in the form

\begin{equation}
  \label{gliss.eq.matrix_full}
  \mathbf{A} \mathbf{x} = \mathbf{b},
\end{equation}

\noindent
or more fully,

\begin{equation}
  \label{gliss.eq.matrix}
  \begin{matrix}
    \left[ \begin{matrix}
        \mathbf{A}_{\mathbf{uu}} & \mathbf{A}_{\mathbf{uv}}  \\
        \mathbf{A}_{\mathbf{vu}} & \mathbf{A}_{\mathbf{vv}}  \\
      \end{matrix} \right]\left[ \begin{matrix}
        \mathbf{u}  \\
        \mathbf{v}  \\
      \end{matrix} \right]=\left[ \begin{matrix}
        \mathbf{b}_{\mathbf{u}}  \\
        \mathbf{b}_{\mathbf{v}}  \\
      \end{matrix} \right]. \\ 
    \\ 
%    \mathbf{A}_{\mathbf{uu}}\mathbf{u} + \mathbf{A}_{\mathbf{uv}}\mathbf{v} =\mathbf{b}_{\mathbf{u}},
%    \quad \quad \mathbf{A}_{\mathbf{vu}}\mathbf{u} + \mathbf{A}_{\mathbf{vv}}\mathbf{v} =\mathbf{b}_{\mathbf{v}}. \\ 
  \end{matrix}
\end{equation}

\noindent
Eq. \eqref{gliss.eq.matrix} shows the four parts of the global matrix $\mathbf{A}$,
with the solution and right-hand-side vectors separated into $u$ and $v$ components.
In Glissade, $\mathbf{A}$ is always symmetric and positive-definite.

Since $\mathbf{A}$ depends (through $\eta$) on $u$ and $v$, the problem is nonlinear and must be solved iteratively.
For each nonlinear iteration, Glissade computes $\eta$ based on the
current guess for the velocity field and then solves a linear problem of the form \eqref{gliss.eq.matrix}.
Then $\eta$ is updated and the process is repeated until the solution converges to within a given tolerance.
This procedure is known as Picard iteration.

The following sections describe how the matrix equations are assembled and solved. 

\subsubsection{Assembly}

The coupled PDEs \eqref{gliss.eq.stress_balance} are discretized using the finite-element method.
Here we give a detailed but non-rigorous description of the method as applied to the Blatter-Pattyn
approximation on the CISM mesh.
We refer the reader to standard texts (\textit{add one or two references here}) 
for a full discussion of finite elements.

The PDEs, with appropriate boundary conditions, are converted to a system of algebraic equations
by dividing the full domain into subdomains (i.e., elements), representing the velocity solution on each element,
and then integrating over elements. On the CISM mesh, the elements are hexahedra (rectangles
in map view), each of which has eight nodes shared with its neighbors.
The solution is approximated as a sum over basis functions $\varphi$. 
Each active node is associated with a basis function whose value is $\varphi = 1$ at that node,
with $\varphi = 0$ at all other nodes. The solution at a point
within an element can be expanded as a sum of basis functions (evaluated at that point)
multiplied by nodal values:

\begin{equation}
\label{gliss.eq.velo_expansion}  
   u(x,y,z) = \sum\limits_{n}{{{\varphi }_{n}(x,y,z)}{{u}_{n}}}, \quad 
   v(x,y,z) = \sum\limits_{n}{{{\varphi }_{n}(x,y,z)}{{v}_{n}}},  \\
\end{equation}

\noindent
where the sum is over the nodes of the element, $u_n$ and $v_n$ are nodal
values of the solution, and $\varphi_n$ varies smoothly between 0 and 1 within the element.
The fact that $\varphi = 0$ except in a small region ensures that the sum includes only
as many terms as there are nodes per element.

Glissade uses standard finite-element techniques to represent the PDE on each element and assemble
the element equations into a global set of algebraic equations of the form \eqref{gliss.eq.matrix}.
The scheme is formally equivalent to that described by \citet{Perego2012} (henceforth PGB).
Note that \eqref{gliss.eq.stress_balance} can be written as

\begin{equation}
  \label{gliss.eq.Perego12}
  \begin{split}
    -\nabla \cdot (2\eta {{{\dot{\varepsilon }}}_{1}}) = -\rho g\frac{\partial s}{\partial x}, \\
    -\nabla \cdot (2\eta {{{\dot{\varepsilon }}}_{2}}) = -\rho g\frac{\partial s}{\partial y}, \\
  \end{split}
\end{equation}

\noindent
where

\begin{equation}
  \label{gliss.eq.Perego13}
  {{{\dot{\varepsilon }}}_{1}}=\left[ \begin{matrix}
      2{{{\dot{\varepsilon }}}_{xx}}+{{{\dot{\varepsilon }}}_{yy}} \\ 
      {{{\dot{\varepsilon }}}_{xy}} \\ 
      {{{\dot{\varepsilon }}}_{xz}} \\ 
    \end{matrix} \right], \quad
  {{{\dot{\varepsilon }}}_{2}}=\left[ \begin{matrix}
      {{{\dot{\varepsilon }}}_{xy}} \\ 
      {{{\dot{\varepsilon }}}_{xx}}+2{{{\dot{\varepsilon }}}_{yy}} \\ 
      {{{\dot{\varepsilon }}}_{yz}} \\ 
    \end{matrix} \right].  \\
\end{equation}

\noindent
(These are Eqs. 12 and 13 in PGB.)  We rewrite the equations in \textit{weak form} (see PGB Eq. 15), which
is obtained by multiplying \eqref{gliss.eq.Perego12} by the basis functions and integrating over the domain, using 
integration by parts to eliminate the second derivative:

\begin{equation}
  \label{gliss.eq.weak_form}
  \begin{split}
    x: \quad \int\limits_{\Omega } {2\eta {{{\dot{\varepsilon }}}_{1}}(u,v)\cdot \nabla {{\varphi }_{1}} \text{ d}\Omega }
      + \int\limits_{{\Gamma }_{B}} {\beta u{{\varphi }_{1}} \text{ d}\Gamma} 
      + \int\limits_{{\Gamma }_{L}} {p n_1 {{\varphi }_{1}} \text{ d}\Gamma}
      + \int\limits_{\Omega } {\rho g\frac{\partial s}{\partial x}{{\varphi }_{1}} \text{ d}\Omega}
      = \text{0},  \\
    y: \quad \int\limits_{\Omega } {2\eta {{{\dot{\varepsilon }}}_{2}}(u,v)\cdot \nabla {{\varphi }_{2}} \text{ d}\Omega }
      + \int\limits_{{\Gamma }_{B}} {\beta u{{\varphi }_{2}} \text{ d}\Gamma} 
      + \int\limits_{{\Gamma }_{L}} {p n_2 {{\varphi }_{2}} \text{ d}\Gamma}
      + \int\limits_{\Omega } {\rho g\frac{\partial s}{\partial y}{{\varphi }_{2}} \text{ d}\Omega}
      = \text{0},  \\
  \end{split}
\end{equation}

\noindent
where $\Omega$ represents the domain volume, $\Gamma_{B}$ denotes the lower boundary, $\Gamma_{L}$ denotes the lateral
boundary (e.g., the calving front of an ice shelf), $\beta$ is a basal traction parameter, $p$ is the pressure at the 
lateral boundary, and $n_1$ and $n_2$ are components of the normal to $\Gamma_L$.
These equations can also be obtained from a variational principle as described by \citet{DUKOWICZ:2010wb}.

The four terms of \eqref{gliss.eq.weak_form} describe internal ice streses, basal friction, lateral pressure,
and the gravitational driving force, respectively.  Next we describe how these terms are summed over elements
and assembled into the global matrix $\mathbf{A}$ and right-hand side vector $\mathbf{b}$.

\paragraph{Internal ice stresses.}

We start with the internal stress term, which is the most complex.
We can rewrite the first term on the left-hand side of \eqref{gliss.eq.weak_form} in terms of velocity components:

\begin{equation}
  \label{gliss.eq.weak_form_velo}
  \begin{aligned}
    & x: \int\limits_{\Omega }{2\eta \left[ \begin{matrix}
          2\frac{\partial u}{\partial x}+\frac{\partial v}{\partial y} & \frac{1}{2}\left( \frac{\partial u}{\partial y}+\frac{\partial v}{\partial x} \right) & \frac{1}{2}\frac{\partial u}{\partial z}  \\
\end{matrix} \right]}\left\{ \begin{matrix}
      \frac{\partial \varphi }{\partial x}  \\[6pt]
      \frac{\partial \varphi }{\partial y}  \\[6pt]
      \frac{\partial \varphi }{\partial z}  \\
    \end{matrix} \right\},  \\
    & y: \int\limits_{\Omega }{2\eta \left[ \begin{matrix}
          \frac{1}{2}\left( \frac{\partial u}{\partial y}+\frac{\partial v}{\partial x} \right) & 2\frac{\partial v}{\partial y}+\frac{\partial u}{\partial x} & \frac{1}{2}\frac{\partial v}{\partial z}  \\
        \end{matrix} \right]}\left\{ \begin{matrix}
      \frac{\partial \varphi }{\partial x}  \\[6pt]
      \frac{\partial \varphi }{\partial y}  \\[6pt]
      \frac{\partial \varphi }{\partial z}  \\
    \end{matrix} \right\},  \\
  \end{aligned}
\end{equation}

\noindent
where brackets are used for row vectors and braces for column vectors.
Glissade evaluates \eqref{gliss.eq.weak_form_velo} for each active element.  Recall that hexahedral elements have eight nodes,
with $u$ and $v$ to be determined at each active node.
Inserting the velocity expressions \eqref{gliss.eq.velo_expansion} in \eqref{gliss.eq.weak_form_velo}, we obtain

\begin{equation}
  \label{gliss.eq.element_matrix}
  \begin{split}
    x: \int\limits_{\Omega }{2\eta \left( \frac{\partial {{\varphi }_{i}}}{\partial x}\left( 2\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{u}_{j}} \right\}+\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{v}_{j}} \right\} \right)+\frac{\partial {{\varphi }_{i}}}{\partial y}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{u}_{j}} \right\}+\frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{v}_{j}} \right\} \right)+\frac{\partial {{\varphi }_{i}}}{\partial z}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial z} \right]\left\{ {{u}_{j}} \right\} \right) \right)},  \\
    y: \int\limits_{\Omega }{2\eta \left( \frac{\partial {{\varphi }_{i}}}{\partial y}\left( 2\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{v}_{j}} \right\}+\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{u}_{j}} \right\} \right)+\frac{\partial {{\varphi }_{i}}}{\partial x}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{v}_{j}} \right\}+\frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{u}_{j}} \right\} \right)+\frac{\partial {{\varphi }_{i}}}{\partial z}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial z} \right]\left\{ {{v}_{j}} \right\} \right) \right)}.  \\
  \end{split}
\end{equation}

\noindent
Each row or column vector has eight terms, one for each node of the element.
These terms can be evaluated to form a set of four $8\text{x}8$ element matrices.
Each row of an element matrix is associated with $u$ or $v$ at a given node.  The columns in that row contain terms
linking that node to $u$ or $v$ at the other nodes of the element (with the diagonal term linking the node to itself).  

In the $x$ component of \eqref{gliss.eq.element_matrix}, 
the terms that multiply $u_j$ are given by
 
\begin{equation}
  \label{gliss.eq.matrix_Kuu}
  \int\limits_{\Omega }{\eta \left( 4\frac{\partial {{\varphi }_{i}}}{\partial x}\frac{\partial {{\varphi }_{j}}}{\partial x} +
    \frac{\partial {{\varphi }_{i}}}{\partial y}\frac{\partial {{\varphi}_{j}}}{\partial y} + 
    \frac{\partial {{\varphi }_{i}}}{\partial z}\frac{\partial {{\varphi }_{j}}}{\partial z} \right)}d\Omega
\end{equation}

\noindent
Letting $i$ and $j$ range from 1 to 8, \eqref{gliss.eq.matrix_Kuu} gives the 64 terms of the $8\text{x}8$ element matrix $\mathbf{K_{uu}}$,
which links the $u$ value at each node to the $u$ values at all eight nodes.
Similarly, the 64 terms of element matrix $\mathbf{K_{uv}}$, which links $u$ at a given node to $v$ at all eight nodes,
are given by

\begin{equation}
  \label{gliss.eq.matrix_Kuv}
  \int\limits_{\Omega }{\eta \left( 2\frac{\partial {{\varphi }_{i}}}{\partial x}\frac{\partial {{\varphi }_{j}}}{\partial y}+\frac{\partial {{\varphi }_{i}}}{\partial y}\frac{\partial {{\varphi }_{j}}}{\partial x} \right)}d\Omega
\end{equation}

Likewise, two $8\text{x}8$ matrices are associated with the $y$ component of \eqref{gliss.eq.element_matrix}.  
The terms of $\mathbf{K_{vu}}$, which connects $v$ at a given node to $u$ at all nodes, are given by

\begin{equation}
  \label{gliss.eq.matrix_Kvu}
  \int\limits_{\Omega }{\eta \left( 2\frac{\partial {{\varphi }_{i}}}{\partial y}\frac{\partial {{\varphi }_{j}}}{\partial x}+\frac{\partial {{\varphi }_{i}}}{\partial x}\frac{\partial {{\varphi }_{j}}}{\partial y} \right)}d\Omega
\end{equation}

\noindent
Finally, the terms of $\mathbf{K_{vv}}$, which links $v$ at a given node to $v$ at all nodes, are given by

\begin{equation}
  \label{gliss.eq.matrix_Kvv}
  \int\limits_{\Omega }{\eta \left( 4\frac{\partial {{\varphi }_{i}}}{\partial y}\frac{\partial {{\varphi }_{j}}}{\partial y}+\frac{\partial {{\varphi }_{i}}}{\partial x}\frac{\partial {{\varphi}_{j}}}{\partial x}+\frac{\partial {{\varphi }_{i}}}{\partial z}\frac{\partial {{\varphi }_{j}}}{\partial z} \right)}d\Omega
\end{equation}

Because of the symmetry of the underlying PDEs, $\mathbf{K_{uu}}$ and $\mathbf{K_{vv}}$ are symmetric,
and $\mathbf{K_{uv}} = \mathbf{K_{vu}}^{T}$.  Note that $\mathbf{K_{vv}}$ can be obtained from $\mathbf{K_{uu}}$, 
and $\mathbf{K_{vu}}$ from $\mathbf{K_{uv}}$, by exchanging $x$ and $y$.  The terms
containing $z$ (i.e., the vertical shear stresses associated with the shallow-ice approximation)
appear only in $\mathbf{K_{uu}}$ and $\mathbf{K_{vv}}$.  The terms containing $x$ and $y$ (i.e.,
the membrane stresses) appear in all four element matrices.

Eqs. \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv} lie at the heart of the code 
(in subroutine \textit{compute\_element\_matrix} of module \textit{glissade\_velo\_higher.F90}).
Together with the expressions for the effective viscosity $\eta$ (discussed below),
these expressions contain the physical contents of the Blatter-Pattyn approximation. 

In the weak form of the equations, each of the 64 coefficients in each
element matrix must be integrated over the element.  (Since $\varphi$ varies over the element,
the integrands in \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv} 
have a different value at each point.)  
This is done for a given element by evaluating the integrand at each of 
eight \textit{quadrature points} and summing over quadrature points.
We first have to specify the form of the basis functions, then transform the basis functions to
the geometry of the element (which is irregular in the vertical because of the sigma
coordinate) and evaluate the basis function derivatives at the quadrature points.

Glissade uses trilinear basis functions defined on a reference cube.  
This cube is centered at the origin $(0,0,0)$ in local reference coordinates 
$(\hat{x}, \hat{y}, \hat{z}$). 
The eight nodes are located at $(\hat{x}, \hat{y}, \hat{z}) = (\pm 1, \pm 1, \pm 1)$.
By convention, nodes 1--4 are the nodes of the lower face, proceeding counterclockwise
from the southwest corner $(\hat{x}, \hat{y}) = (-1, -1)$, and nodes 5--8 are the nodes
of the upper face, also moving counterclockwise from the southwest corner.
Thus we have

\begin{equation}
  \label{gliss.eq.basis_functions}
  \begin{matrix}
    {{\varphi }_{1}}=(1-\hat{x})(1-\hat{y})(1-\hat{z})/8,  \\[3pt]
    {{\varphi }_{2}}=(1+\hat{x})(1-\hat{y})(1-\hat{z})/8,  \\[3pt]
    {{\varphi }_{3}}=(1+\hat{x})(1+\hat{y})(1-\hat{z})/8,  \\[3pt]
    {{\varphi }_{4}}=(1-\hat{x})(1+\hat{y})(1-\hat{z})/8,  \\[3pt]
    {{\varphi }_{5}}=(1-\hat{x})(1-\hat{y})(1+\hat{z})/8,  \\[3pt]
    {{\varphi }_{6}}=(1+\hat{x})(1-\hat{y})(1+\hat{z})/8,  \\[3pt]
    {{\varphi }_{7}}=(1+\hat{x})(1+\hat{y})(1+\hat{z})/8,  \\[3pt]
    {{\varphi }_{8}}=(1-\hat{x})(1+\hat{y})(1+\hat{z})/8.  \\
  \end{matrix}
\end{equation} 

\noindent
For each $n$ we have $\varphi_n = 1$ at a single node, with $\varphi_n = 0$ at the other nodes.

The integrands in \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv} 
are written in terms of real Cartesian coordinates $(x,y,z)$ rather than reference coordinates
$(\hat{x},\hat{y},\hat{z})$.
Spatial derivatives in real coordinates are related to derivatives in reference coordinates by

\begin{equation}
  \label{gliss.eq.real_to_reference}
  \scalebox{1.2}{
    $
  \left\{ \begin{matrix}
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{z}}  \\
  \end{matrix} \right\} = 
  \left[ \begin{matrix}
      \frac{\partial x}{\partial \hat{x}} & \frac{\partial y}{\partial \hat{x}} & \frac{\partial z}{\partial \hat{x}}  \\[6pt]
      \frac{\partial x}{\partial \hat{y}} & \frac{\partial y}{\partial \hat{y}} & \frac{\partial z}{\partial \hat{y}}  \\[6pt]
      \frac{\partial x}{\partial \hat{z}} & \frac{\partial y}{\partial \hat{z}} & \frac{\partial z}{\partial \hat{z}}  \\
    \end{matrix} \right]
  \left\{ \begin{matrix}
    \frac{\partial {{\varphi }_{n}}}{\partial x}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial y}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial z}  \\
  \end{matrix} \right\} =
   [J]\left\{ \begin{matrix}
     \frac{\partial {{\varphi }_{n}}}{\partial x}  \\[6pt]
     \frac{\partial {{\varphi }_{n}}}{\partial y}  \\[6pt]
     \frac{\partial {{\varphi }_{n}}}{\partial z}  \\
   \end{matrix} \right\},
   $
  }
\end{equation}

\noindent
where $[J]$ is the Jacobian of the transformation between coordinate systems.  
Given the finite-element expansion

\begin{equation}
   x = \sum\limits_{n}{{{\varphi }_{n}}{{x}_{n}}},
\end{equation}

\noindent
along with the spatial derivatives of $\varphi$ at $(\hat{x},\hat{y},\hat{z})$
(which are easily derived from \eqref{gliss.eq.basis_functions}),
we can compute $[J(\hat{x},\hat{y},\hat{z})]$ as

\begin{equation}
  \label{gliss.eq.Jacobian_eval}
  \scalebox{1.2}{
  $
        [J]=\left[ \begin{matrix}
            \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}{{x}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}{{y}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}{{z}_{n}}}  \\[6pt]
            \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}{{x}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}{{y}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}{{z}_{n}}}  \\[6pt]
            \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{z}}{{x}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{z}}{{y}_{n}}} & \sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{z}}{{z}_{n}}}  \\
          \end{matrix} \right].
        $
        }
\end{equation}

\noindent
We then invert \eqref{gliss.eq.real_to_reference} to obtain the 
basis function derivatives in terms of $(x,y,z)$:

\begin{equation}
  \label{gliss.eq.reference_to_real}
  \scalebox{1.2}{
    $
  \left\{ \begin{matrix}
     \frac{\partial {{\varphi }_{n}}}{\partial x}  \\[6pt]
     \frac{\partial {{\varphi }_{n}}}{\partial y}  \\[6pt]
     \frac{\partial {{\varphi }_{n}}}{\partial z}  \\
  \end{matrix} \right\} =
          [J^{-1}]  \left\{ \begin{matrix}
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{z}}  \\
  \end{matrix} \right\}. 
          $
          }
\end{equation}

\noindent
The left-hand side of \eqref{gliss.eq.reference_to_real} contains the spatial derivatives 
appearing in \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv}.

Eqs. \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv} also contain the viscosity $\eta$,
which is computed at each quadrature point.
In the Blatter-Pattyn approximation, $\eta$ is given by \eqref{gliss.eq.effective_viscosity};
it is a function of the flow factor $A$ and the effective strain rate defined by \eqref{gliss.eq.effective_strain_rate}.
We approximate $A$ by its value at the element center.
The (squared) effective strain rate, ${{\dot{\varepsilon }}^{2}}_{e}$, is evaluated at each quadrature point
by summing over strain-rate components.  The $x$ components are given by

\begin{equation}
  \label{gliss.eq.strain_rates}
  \frac{\partial u}{\partial x}=\sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial x}}{{u}_{n}}, \quad
  \frac{\partial v}{\partial x}=\sum\limits_{n=1}^{8}{\frac{\partial {{\varphi }_{n}}}{\partial x}}{{v}_{n}},
\end{equation}

\noindent
and similarly for the $y$ and $z$ components.  The nodal velocities in \eqref{gliss.eq.strain_rates}
are values from the previous iteration; otherwise the resulting system of equations would be nonlinear.

We now have the information needed to compute the integrands \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv}
at quadrature points. To integrate over a hexahedron, we take a weighted sum of the values at each
of eight quadrature points.  These points are located at
reference coordinates $(\hat{x},\hat{y},\hat{z}) = (\pm 1/\sqrt{3}, \pm 1/\sqrt{3}, \pm 1\sqrt{3})$.
Thus, to evaluate an integral of the form

\begin{equation}
  \int\limits_{\Omega }{\eta \left( \frac{\partial {{\varphi }_{i}}}{\partial z}\frac{\partial {{\varphi }_{j}}}{\partial z} \right)}d\Omega
\end{equation}

\noindent
over element volume $\Omega$, we compute the sum over quadrature points

\begin{equation}
  \label{gliss.eq.sum_over_qp}
  \sum\limits_{p=1}^{8}{{{w}_{p}}{{\eta }_{p}}{{\left( \frac{\partial {{\varphi }_{i}}}{\partial z}\frac{\partial {{\varphi }_{j}}}{\partial z} \right)}_{p}}}|J_p|,
\end{equation}

\noindent
where $|J|$ is the determinant of the Jacobian \eqref{gliss.eq.Jacobian_eval}. For this choice of quadrature points,
each point has $w_p = 1$.

The terms of the element matrices $\mathbf{K_{uu}}, \mathbf{K_{uv}}, \mathbf{K_{vu}}$ and $\mathbf{K_{vv}}$
are then inserted into the corresponding global matrices $\mathbf{A_{uu}}, \mathbf{A_{uv}}, \mathbf{A_{vu}}$ and $\mathbf{A_{vv}}$.
This is mostly a matter of bookkeeping.
For example, the first row of $\mathbf{K_{uu}}$ corresponds to a particular node of element $(k,i,j)$
(specifically, the node with indices $(k-1,i-1,j-1)$, given our convention for numbering nodes within elements).  
This row is mapped to a row of the global matrix $\mathbf{A_{uu}}$, 
and each of the eight terms in this row is associated with a column of $\mathbf{A_{uu}}$.  
Glissade determines the correct column
and adds the $\mathbf{K_{uu}}$ term to the corresponding term in $\mathbf{A_{uu}}$.  This process proceeds
until the code has looped over all the active elements and filled the global matrices.

If written in full, each global matrix would have as many rows and columns as there are active nodes.
These matrices, however, are sparse, with a maximum of 27 nonzero terms per row (corresponding to
a node and its 26 nearest neighbors in a 3D hexahedral lattice).
Glissade therefore assembles and stores global matrices of dimension $(27,nz,nx-1,ny-1)$.
The 27 terms of the first dimension are indexed such that each index has a geometric meaning.
Suppose we are labeling columns for the matrix row corresponding to node $(k,i,j)$. 
Then, for example, index 1 labels the node with coordinates $(k-1,i-1,j-1)$, index 14 labels the
node itself (i.e., the diagonal term of the row), and index 27 labels the node at $(k+1,i+1,j+1)$.
The global matrices can be reformatted as needed before being passed to a particular solver. 

The remaining assembly consists of evaluating the other terms in \eqref{gliss.eq.weak_form}
(i.e., the basal and lateral boundary conditions and the gravitational forcing) and implementing
Dirichlet boundary conditions, if applicable. We consider these in turn.

\paragraph{Basal boundary conditions.}

At the basal boundary we assume a friction law of the form 

\begin{equation}
  \label{gliss.eq.beta_tau}
  \mathbf{\tau_b} = -\beta \mathbf{u_b}.  
\end{equation}

\noindent
The coefficient $\beta$ is defined at each vertex and can vary spatially.  
If $\beta$ depends on the velocity, as in some friction laws,
then it is calculated using the velocity from the previous iteration.

The basal boundary terms to be evaluated in \eqref{gliss.eq.weak_form} are

\begin{equation}
  \label{gliss.eq.basal_bc}
  \begin{split}
    x: \int\limits_{{\Gamma }_{B}} \beta u{{\varphi }_{1}} d\Gamma , \\
    y: \int\limits_{{\Gamma }_{B}} \beta v{{\varphi }_{2}} d\Gamma . \\
  \end{split}
\end{equation}

\noindent
The basal face of each cell is a rectangle. To integrate over a rectangle, we 
sum over terms at four quadrature points.  These points lie at $(\hat{x},\hat{y}) = (\pm 1/\sqrt{3}, \pm 1/\sqrt{3}$)
in a reference square with center $(0,0)$ and vertices $(\pm1,\pm1)$.
(This reference square is the 2D analog of the reference cube discussed above.)
We define four bilinear basis functions on the square (cf. \eqref{gliss.eq.basis_functions}):

\begin{equation}
  \label{gliss.eq.basis_functions_2d}
  \begin{matrix}
    {{\varphi }_{1}}=(1-\hat{x})(1-\hat{y})/4,  \\[3pt]
    {{\varphi }_{2}}=(1+\hat{x})(1-\hat{y})/4,  \\[3pt]
    {{\varphi }_{3}}=(1+\hat{x})(1+\hat{y})/4,  \\[3pt]
    {{\varphi }_{4}}=(1-\hat{x})(1+\hat{y})/4.
  \end{matrix}
\end{equation}

\noindent
Given these basis functions and their spatial derivatives, we can compute the Jacobian
for the transformation between the reference square and the rectangular cell face,
using the 2D versions of \eqref{gliss.eq.Jacobian_eval} and \eqref{gliss.eq.reference_to_real}:

\begin{equation}
  \label{gliss.eq.Jacobian_eval_2d}
  \scalebox{1.2}{
  $
        [J]=\left[ \begin{matrix}
            \sum\limits_{n=1}^{4}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}{{x}_{n}}} & \sum\limits_{n=1}^{4}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}{{y}_{n}}} \\[6pt]
            \sum\limits_{n=1}^{4}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}{{x}_{n}}} & \sum\limits_{n=1}^{4}{\frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}{{y}_{n}}} \\[6pt]
          \end{matrix} \right],
        $
        }
\end{equation}

\begin{equation}
  \label{gliss.eq.reference_to_real_2d}
  \scalebox{1.2}{
    $
  \left\{ \begin{matrix}
     \frac{\partial {{\varphi }_{n}}}{\partial x}  \\[6pt]
     \frac{\partial {{\varphi }_{n}}}{\partial y}  \\
  \end{matrix} \right\} =
          [J^{-1}]  \left\{ \begin{matrix}
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{x}}  \\[6pt]
    \frac{\partial {{\varphi }_{n}}}{\partial \hat{y}}  \\
  \end{matrix} \right\}. 
          $
          }
\end{equation}

The integrand at a quadrature point has the form
\begin{equation}
  \label{gliss.eq.beta_integrand}
  \beta \varphi_i \varphi_j,
\end{equation}

\noindent
where the second $\varphi$ term arises from the finite-element expansion of $u$ at a quadrature point:

\begin{equation}
  u = \sum\limits_{n=1}^{4} {u_n \varphi_n}.
\end{equation}

\noindent
We determine $\beta$ at quadrature points from the values at cell vertices:

\begin{equation}
  \beta = \sum\limits_{n=1}^{4} {\beta_n \varphi_n}.
\end{equation}

\noindent
The integral of \eqref{gliss.eq.beta_integrand} over a cell is then computed as a sum over quadrature points:

\begin{equation}
  \label{gliss.eq.sum_over_qp_beta}
  \sum\limits_{p=1}^{4} {w_p \beta_p (\varphi_i \varphi_j)_p |J_p|},
\end{equation}

\noindent
where $w_p = 1$ for each point.  This procedure generates a 4\text{x}4 matrix
describing the connections between each node and its neighbors in the cell.
%This is a 2D analog of the element matrices discussed above.  
Since the $x$ term in \eqref{gliss.eq.basal_bc} 
contains $u$ but not $v$, and the $y$ term contains
$v$ but not $u$, we form 2D matrices $\mathbf{K_{uu}}$ and $\mathbf{K_{vv}}$, but not $\mathbf{K_{uv}}$ and $\mathbf{K_{vu}}$.
Each term of $\mathbf{K_{uu}}$ is then inserted into the global matrix $\mathbf{A_{uu}}$, and
similarly for $\mathbf{K_{vv}}$ and $\mathbf{A_{vv}}$.

(\textbf{Add a paragraph here on plastic bed conditions.})

\paragraph{Lateral boundary conditions.}

The lateral boundary terms in \eqref{gliss.eq.weak_form} are

\begin{equation}
  \label{gliss.eq.lateral_bc}
  \begin{split}
    x: \int\limits_{{\Gamma }_{L}} {p n_1 {{\varphi }_{1}} \text{ d}\Gamma}, \\
    y: \int\limits_{{\Gamma }_{L}} {p n_2 {{\varphi }_{2}} \text{ d}\Gamma}.
  \end{split}
\end{equation}

\noindent
Since these terms are independent of $u$ and $v$, they contribute to the load vectors
$\mathbf{b_u}$ and $\mathbf{b_v}$ on the right-hand side of \eqref{gliss.eq.matrix}.
They are integrated over the lateral faces of floating cells that border the ocean.
(Grounded cells are assumed to have no lateral forcing.)

The lateral faces bordering the ocean are quadrilaterals that can be mapped to a reference square.
As for the basal boundary terms, the integral over each face is found by 
summing over four quadrature points.
Basis functions are given by \eqref{gliss.eq.basis_functions_2d}, and
the Jacobian of the reference square is computed using \eqref{gliss.eq.Jacobian_eval_2d}.
We evaluate the ice thickness $H$ at each quadrature point using

\begin{equation}
  \label{gliss.eq.thickness_qp}
  H = \sum\limits_{n=1}^{4} {H_n \varphi_n},
\end{equation}

\noindent
where the $H_n$ are nodal values.
%(Each lateral face contains two pairs of nodes aligned in the vertical; aligned nodes
%have the same values for $H$ and $s$.) 
The integrands have the form $p_n \varphi$, where $p_n$ is the vertically averaged
net pressure normal to the ice edge.  
(We use the vertically averaged pressure to avoid issues with vertical shearing at the ice edge.)
The net pressure is equal to the pressure
directed outward from the ice toward the ocean by the weight of the ice, minus the (smaller)
pressure directed inward from the ocean to the ice by the hydrostatic water pressure.
The outward pressure is obtained by integrating $\rho_i g (s-z) dz$ from $s-H$ to $s$
and then dividing by $H$; it is given by 

\begin{equation}
  \label{gliss.eq.lateral_pout}
  p_{\text{out}} = \frac{\rho_i g H}{2},
\end{equation}

\noindent
The inward pressure is found by integrating $(-\rho_w g z dz)$ from $s-H$ to 0
and then dividing by $H-s$; it is given by

\begin{equation}
  \label{gliss.eq.lateral_pin1}
  p_{\text{in}} = \frac{\rho_w g (s-H)^2}{2H}
\end{equation}

\noindent
Assuming hydrostatic balance, we have $s-H = (\rho_i/\rho_w)H$. Thus \eqref{gliss.eq.lateral_pin1} becomes

\begin{equation}
  \label{gliss.eq.lateral_pin2}
  p_{\text{in}} = \frac{\rho_i g H}{2} \frac{\rho_i}{\rho_w}
\end{equation}

\noindent
Combining \eqref{gliss.eq.lateral_pout} and \eqref{gliss.eq.lateral_pin2} gives

\begin{equation}
  \label{gliss.eq.lateral_pnet}
  p_{\text{net}} = \frac{\rho_i g H}{2} \left(1 - \frac{\rho_i}{\rho_w}\right),
\end{equation}

\noindent
directed from the ice to the ocean.  
The integral of the pressure terms over a lateral face is then found as a sum over quadrature points:

\begin{equation}
  \label{gliss.eq.sum_over_qp_lateral}
  \sum\limits_{p=1}^{4} {\pm w_p (p_\text{net})_p (\varphi_i)_p |J_p|},
\end{equation}

\noindent
where the sign depends on the orientation of the face.  The resulting pressure terms
are inserted into the load vector (either $\mathbf{b_u}$ or $\mathbf{b_v}$, depending on the orientation)
associated with each of the four nodes of the face.

\paragraph{Gravitational driving stress.}

The gravitational forcing terms in \eqref{gliss.eq.weak_form} are

\begin{equation}
  \label{gliss.eq.gravity_forcing}
  \begin{split}
    x: \int\limits_{\Omega } {\rho g\frac{\partial s}{\partial x}} {{\varphi }_{1}}\text{ d}\Omega, \\
    y: \int\limits_{\Omega } {\rho g\frac{\partial s}{\partial y}} {{\varphi }_{2}}\text{ d}\Omega. \\
  \end{split}
\end{equation}

\noindent
To compute these terms we evaluate $\frac{\partial s}{\partial x}$ and $\frac{\partial s}{\partial y}$
at each active vertex.  A standard centered approximation at vertex $(i,j)$ is

\begin{equation}
  \label{gliss.eq.dsdx_centered}
  \frac{\partial s}{\partial x}(i,j) = \frac{s(i+1,j+1)+s(i+1,j)-s(i,j+1)-s(i,j)}{2\Delta x},
\end{equation}

\noindent
and similarly for $\frac{\partial s}{\partial y}$. This approximation works
well when the ice geometry is fixed but can cause problems when the geometry is evolving.
These problems arise because checkerboard noise in $s$ (which is common on structured meshes
with the velocity at cell vertices) is invisible to the momentum balance; 
it is canceled out by the centered averaging in \eqref{gliss.eq.dsdx_centered}.
Checkerboard noise can therefore persist and grow.  To damp this noise, Glissade uses an upstream average:

\begin{equation}
  \label{gliss.eq.dsdx_upstream}
  \frac{\partial s}{\partial x}(i,j) = \frac{1.5 (s(i+1,j+1) - s(i,j+1)) - 0.5 (s(i+1,j+2) - s(i,j+2))}{\Delta x}.
\end{equation}

\noindent
Here, ``upstream'' means in the direction of increasing surface elevation. Both \eqref{gliss.eq.dsdx_centered}
and \eqref{gliss.eq.dsdx_upstream} are second-order accurate.

The integrals in \eqref{gliss.eq.gravity_forcing} are over 3D elements.
Hence we map each hexahedral element to a reference cube as described above. 
Given $\frac{\partial s}{\partial x}$ at the nodes of a cell,
the surface slope terms at quadrature points are

\begin{equation}
  \frac{\partial s}{\partial x} = \sum\limits_{n=1}^{4}{{{\varphi }_{n}}}{{\left( \frac{\partial s}{\partial x} \right)}_{n}}, \quad
  \frac{\partial s}{\partial y} = \sum\limits_{n=1}^{4}{{{\varphi }_{n}}}{{\left( \frac{\partial s}{\partial y} \right)}_{n}},
\end{equation}

\noindent
where the basis functions $\varphi$ are given by \eqref{gliss.eq.basis_functions}
and the spatial derivatives are derived from \eqref{gliss.eq.Jacobian_eval} and \eqref{gliss.eq.reference_to_real}.
The integral of $\rho g \frac{\partial s}{\partial x} \varphi$
over an element is then evaluated as a sum over quadrature points:

\begin{equation}
  \label{gliss.eq.sum_over_qp_gravity}
  \sum\limits_{p=1}^{8} { w_p \rho g \left(\frac{\partial s}{\partial x}\right)_p (\varphi_i)_p |J_p|},
\end{equation}

\noindent
and similarly for the $\frac{\partial s}{\partial y}$ term.
Glissade inserts these terms into the load vectors $\mathbf{b_u}$ and $\mathbf{b_v}$
associated with each active node of the element.

\paragraph{Dirichlet boundary conditions.}

Once the matrix has been assembled, it may need to be adjusted for Dirichlet boundary conditions
(i.e., prescribed values of the velocity at certain nodes). The most common Dirichlet condition
is to set $u = v = 0$ at the bed to enforce a no-slip boundary condition.  (A no-slip condition
can also be enforced by setting the basal traction coefficient $\beta$
to a large value, but formally this is not a Dirichlet condition.)  Also, it may be desirable to
set $u$ and $v$ to observed values at certain locations, as in the Ross ice shelf test case.

%Suppose $u = u_c$ and $v = v_c$ at node $(k,i,j)$, where $u_c$ and $v_c$ are prescribed values.  
%To enforce this Dirichlet condition, we set $\mathbf{A_{uu}}(m,k,i,j) = \mathbf{A_{vv}}(m,k,i,j) = 1$ 
%for the value of $m$ denoting the diagonal entry in the global matrices, and we set  
%$\mathbf{A_{uu}}(m,k,i,j) = \mathbf{A_{vv}}(m,k,i,j) = 0$ for all other $m$.  In addition, we set
%$\mathbf{A_{uv}}(m,k,i,j) = \mathbf{A_{vu}}(m,k,i,j) = 0$ for all $m$, since these two matrices do not contain
%any terms on the diagonal of the full global matrix (i.e., $A$ in \eqref{gliss.eq.matrix_full}.
%On the right-hand side, we set $b_u(k,i,j) = u_c$ and $b_v(k,i,j) = v_c$.  These operations
%convert the matrix rows associated with node $(k,i,j)$ to the form $1 \cdot u = u_c, 1 \cdot v = v_c$,
%which clearly have the desired solutions $u_c$ and $v_c$.

%A further step is needed to maintain matrix symmetry, as required
%when using a preconditioned conjugate gradient solver. A given node $(k,i,j)$ is associated
%with two columns of the full global matrix (one for $u$ and one for $v$).
%Consider the row of $\mathbf{A_{uu}}$ associated with node $(k+1,i+1,j+1)$.  One term in this row
%(specifically, $\mathbf{A_{uu}}(1,k+1,i+1,j+1)$ in the dense storage format) is linked to node $(k,i,j)$, 
%in that the product of this term and $u(k,i,j) = u_c$ contributes to $b_u(k+1,i+1,j+1)$.
%We can move this term to the right-hand side by subtracting the product from $b_u(k+1,i+1,j+1)$ 
%and zeroing out the term in $\mathbf{A_{uu}}$.
%This is done for all terms of $\mathbf{A_{uu}}$ and the other global matrices that are multiplied by
%$u(k,i,j)$ or $v(k,i,j)$ in the matrix-vector product (i.e., all columns of the full matrix 
%associated with node $(k,i,j)$).
%Thus, both the rows and the columns associated with node $(k,i,j)$ are filled with zeros,
%except for the diagonal term ``1'', and the full global matrix remains symmetric.

Suppose that at node $(k,i,j)$ we have $u = u_c$ and $v = v_c$, where $u_c$ and $v_c$ are prescribed values.  
Let $nr$ be the row of $\mathbf{A_{uu}}$ associated with this node, and let $nc$ range over the various
columns with nonzero entries in this row.
To enforce the Dirichlet condition, we set $\mathbf{A_{uu}}(nr,nc) = \mathbf{A_{vv}}(nr,nc) = 0$ for all
values of $nc$ except $nc = nr$ (the diagonal term); we set $\mathbf{A_{uu}}(nr,nr) = \mathbf{A_{vv}}(nr,nr) = 1$.
In addition, we set $\mathbf{A_{uv}}(nr,nc) = \mathbf{A_{vu}}(nr,nc) = 0$ for all $nc$, since these two matrices do not contain
any terms on the diagonal of the full global matrix (i.e., $\mathbf{A}$ in \eqref{gliss.eq.matrix_full}).
On the right-hand side, we set $\mathbf{b_u}(nr) = u_c$ and $\mathbf{b_v}(nr) = v_c$.  These operations
convert the matrix rows associated with node $(k,i,j)$ to the form $1 \cdot u = u_c, 1 \cdot v = v_c$,
which clearly have the desired solutions $u_c$ and $v_c$.

A further step is needed to maintain matrix symmetry, as required
when using a preconditioned conjugate gradient solver.  Consider the term $\mathbf{A_{uu}}(nr,nc)$,
where $nc$ is a specific column associated with a neighboring node (say, node $(k+1,i+1,j+1))$.
We have already set $\mathbf{A_{uu}}(nr,nc) = 0$, so we need to set $\mathbf{A_{uu}}(nc,nr) = 0$ to maintain
symmetry. The Dirichlet condition is $u(nr) = u_c$. 
In the matrix-vector product, the product $\mathbf{A_{uu}}(nc,nr) u(nr) = \mathbf{A_{uu}}(nc,nr) u_c$
contributes to $\mathbf{b_u}(nc)$.  Thus we can replace $\mathbf{b_u}(nc)$ with 
$\mathbf{b_u}(nc) -  \mathbf{A_{uu}}(nc,nr) u_c$
and then set $\mathbf{A_{uu}}(nc,nr) = 0$ without altering the problem.
We do this for all the terms in the columns associated with node $(k,i,j)$ (i.e., all the
terms multiplied by $u_c$ or $v_c$ in the matrix-vector product).
Thus, both the rows and the columns associated with node $(k,i,j)$ are filled with zeros,
except for the diagonal term, and the full global matrix remains symmetric.

The Dirichlet bookkeeping in the code is a bit different from what is described here, since the 
dense storage format for the global matrices requires indirect indexing of columns.
The underlying idea, however, is the same.

\subsubsection{Solving the linear system}

Once the matrices and right-hand side vectors have been assembled, we solve the linear problem
\eqref{gliss.eq.matrix}.  Glissade supports three kinds of solvers:

\begin{itemize}
\item A native Fortran 90 preconditioned conjugate gradient (PCG) solver
\item Links to the Sparse Linear Algebra Package (SLAP), with options for 
the generalized minimum residual (GMRES) and biconjugate gradient methods
\item Links to Trilinos, with options for PCG and GMRES, preconditioned by
incomplete lower-upper (ILU) factorization or a multigrid method
\end{itemize}

We describe each solver in turn.

\paragraph{Preconditioned conjugate gradient solver.}

The native PCG solver works directly with the assembled matrices
$A_{uu}$, $A_{uv}$, $A_{vu}$, and $A_{vv}$, along with the right-hand side vectors
$b_u$ and $b_v$.  These matrices are passed to one of two PCG solvers:
a ``standard'' solver and a Chronopolous-Gear solver.  The standard method 
for solving $\mathbf{Ax} = \mathbf{b}$ can be summarized as follows:

\begin{itemize}

\item Let $x_0$ denote the initial guess for $x$ ($x_0 = 0$ if no guess is available);
$r = b - Ax$ is the residual vector; $d$ is a conjugate direction vector;
$M$ is a preconditioning matrix: $\alpha, \beta, \eta_0$, $\eta_1$ and $\eta_2$ are scalars;
$q$ and $z$ are work vectors; and $(r,z)$ is the dot product of two vectors.

\item $r_0 = b - A x_0$, $d_0 = 0$, $\eta_0 = 1$ 

\item Do until converged:
  \begin{itemize}
\renewcommand{\labelitemii}{$\star$}
  \item Solve $M z = r$ for $z$ (the preconditioning step)
  \item $\eta_1 = (r,z)$
  \item $\beta = \eta_1/\eta_0$
  \item $d = z + \beta d$
  \item $\eta_0 = \eta_1$
  \item $q = A d$
  \item $\eta_2 = (d,q)$
  \item $\alpha = \eta_1/\eta_2$
  \item $x = x + \alpha d$
  \item $r = r - \alpha q$ (or periodically, set $r = b - A x$ and check for convergence)
  \end{itemize}
\end{itemize}

\noindent
There are two dot products, one matrix-vector product, and one preconditioning step per iteration.
The convergence condition is $\sqrt{(r,r)}/\sqrt{(b,b)} < \epsilon$, where $\epsilon$ is a small tolerance
($10^{-8}$ by default).
The convergence check is done every five iterations, as a compromise
between the expense of an extra matrix-vector multiply and that of unnecessary iterations.

This solver works either in serial or in parallel.  If run in parallel, the dot products
require global sums, and a halo update for $d$ is needed once per iteration.
Halo updates in CISM operate on 2D arrays with horizontal indices $i$ and $j$ (or 3D/4D 
arrays with additional indices).  This is the main reason for
leaving the global matrices and vectors in array form, instead of
converting to a standard matrix storage format such as compressed row storage.
In array form, it is easy to do halo updates of vectors $u$, $v$, $r_u$, $r_v$, $d_u$, $d_v$, etc.

The PCG solver has two preconditioning options:

\begin{itemize}
\item Diagonal (also known as Jacoby) preconditioning, in which the preconditioning matrix $M$ consists
of the diagonal terms of $A$, so that $M$ is trivial to invert.  Convergence with iagonal preconditioning 
is typically slow.
\item Shallow-ice-based preconditioning.  In this case $M$ consists only of the rows and columns of $A$
that link a given node to itself and its immediate neighbors above and below. The matrix $M$ is then
tridiagonal, as in the shallow-ice approximation, and can be inverted efficiently. This preconditioner
works well when the physics is dominated by vertical shear and the horizontal terms are small, but not
as well when membrane stresses are important. Since the preconditioner is local (it consists of
independent column solves), it scales well with increasing numbers of processor cores.
\end{itemize}

\noindent
Other options could be added in the future, but for large problems that require complex preconditioning,
it is probably better to use Trilinos (see below).

For small problems on a modest number of cores, the dominant cost is the matrix-vector
multiply required during each iteration.  For large problems on many cores, however, the global sums become
increasingly expensive.  To reduce the cost of global sums, the standard PCG algorithm can be
replaced by the Chronopoulos-Gear algorithm, which rearranges operations such that both global sums
are done with a single MPI call.  We omit the details here, but refer the reader
to the code comments in module \textit{glissade\_velo\_higher\_pcg.F90}. 

\paragraph{SLAP.}

The Sparse Linear Algebra Package (SLAP) is a set of Fortran routines for solving sparse systems of linear
equations. SLAP was part of the original Glimmer release and is still used to solve the thickness evolution
and temperature advection problems in Glide.  It can also be used to solve higher-order systems in Glissade,
using either GMRES or a biconjugate gradient solver. (These solvers are standard config options, but with a bit of
effort, other solvers could be enabled too.)  The main limitation of SLAP is that it is serial only,
hence unsuited for large problems.

In order for Glissade to use CISM's SLAP routines, it must convert the global matrices and the 
right-hand-side and solution vectors to a SLAP-friendly format. First (before any matrix assembly),
Glissade assigns a unique integer ID to each active node.  Following assembly, the code loops through the matrices
$A_{uu}$, $A_{uv}$, $A_{vu}$ and $A_{vv}$, putting each nonzero entry into a Fortran derived type containing
the row, column and value of each such entry.  Similarly, the current solution and the right-hand side are placed
in SLAP-friendly vectors. This information is passed to CISM's SLAP solver
and ultimately to the various SLAP subroutines.  The SLAP solver returns the velocity solution
and residual vectors, which are copied back into Glissade data structures.

\paragraph{Trilinos.}

Trilinos (\url{trilinos.org}) is a set of solver packages and related software developed at 
Sandia National Laboratories. Under the DOE ISICLES project \url{http://www.csm.ornl.gov/ISICLES/},
the Glam higher-order dycore was parallelized and linked to Trilinos.  The Trilinos links
developed for Glam were later adapted for Glissade.  Trilinos has been tested extensively on
parallel architectures and has been installed on the DOE machines were CISM is typically run.
See Section [insert ref here] for instructions on building CISM with Trilinos.

The key Trilinos interfaces are in a C++ file called ``trilinosGlissadeSolver.cpp'' in directory ``libglimmer-solve'':

\begin{itemize}
\item \textit{initializetgs} is a procedure that sends Trilinos a global ID for each active node.
\item \textit{insertrowtgs} sends Trilinos a row of the matrix (specifically, the global row index, the number of
potentially nonzero column entries, the index and value of each such entry, and the associated right-hand side term).
\item \textit{solvevelocitytgs} returns the velocity solution.
\end{itemize}

Various Glissade subroutines gather the information needed by Trilinos.  Before assembly, Glissade computes
global IDs for each node $(k,i,j)$ on each processor, along with unique indices for each unknown ($u$ and $v$)
on each active node.  Glissade also computes a logical array of dimension (27,nz,nx-1,ny-1)---the same dimension
as the global matrices---whose value is .true. for the potential nonzero entries in these matrices.
After assembly of $A_{uu}$, $b_u$, etc., the nonzero matrix entries are passed to Trilinos, one row at a time.
Following solution, the Trilinos velocity result is copied to Glissade data structures.

Trilinos solver options are set in a file called ``trilinosOptions.xml'' in the executable directory.
Among the key settings are the solver type and preconditioner type.  The default solver type is Block GMRES.
The default preconditioner type is Ifpack, which applies ILU preconditioning.  ILU generally works well
for problems where shallow-ice physics is dominant, but can struggle for shelf-type problems where
membrane stresses are dominant.  For these problems the ML preconditioner type, which uses a multigrid
method for preconditioning, is likely to work better.  Optimal Trilinos settings for large, physically complex
problems are an area of active research.

Choosing among the various solver options is to some degree an art.  The default is native PCG using
the Chronopoulos-Gear algorithm.  The PCG solver runs efficiently on most platforms and scales well.
On the other hand, its preconditioning options are limited, so convergence may be slow for problems
with dominant membrane stresses.  SLAP solvers are generally robust and efficient, but are limited
to one processor.  Trilinos is typically slower than the other solvers, in part because of the
extra cost of setting up Trilinos data structures, as well as the slower performance of C++ code
relative to Fortran on many platforms.  On the other hand, Trilinos contains a vast range of
solver options (only some of which have been tested to date with CISM) that are likely to 
be more flexible and robust than those implemented in SLAP and the native PCG solver.

\subsubsection{Solving the nonlinear system}

Each call to a linear solver (native PCG, SLAP, or Trilinos) returns a solution vector,
along with the number of iterations and the error, defined as $\sqrt{(r,r)}/\sqrt{(b,b)}$.
If the linear solution fails to converge after the maximum allowed number of iterations
(typically 200), the solve exits with the last computed solution (which may be adequate
despite being unconverged).

Then a new global matrix is assembled, using the latest velocity solution to compute 
the effective viscosity.  The right-hand is adjusted as needed to incorporate Dirichlet
boundary conditions.  Glissade then computes the new residual $b - Ax$.  If the $L_2$ norm of the
residual (defined as $\sqrt{(r,r)}$ is smaller than a desired threshold ($10^{-4}$ by default),
the nonlinear system of equations is considered solved.
\textit{(Change absolute to relative threshold?)}
Otherwise the linear solver is called again, until either the solution converges or the 
maximum number of nonlinear iterations (typically 100) is reached.

As mentioned above, the procedure of updating the matrix with the latest guess for the solution
is known as Picard iteration.  The older Glam dycore includes an option
to solve the nonlinear system using a Jacobian-Free Newton-Krylov (JFNK) method.
JFNK requires an extra residual evaluation per nonlinear iteration, but generally
converge in fewer iterations than does the Picard method.  Glissade, however, does not
have a JFNK option.


\subsection{Other Stokes approximations}
\label{sc:glissade-other-approx}

In addition to the 3D Blatter-Pattyn approximation, Glissade can solve the simpler shallow-shelf
and shallow-ice approximations.  Many of the steps are similar to those described in
Section \ref{sc:glissade-blatter-pattyn}.

\subsubsection{Shallow-shelf approximation}

The shallow-shelf equations can be obtained by vertically integrating the 3D Blatter-Pattyn equations.
They are valid when the basal shear stress is small or zero and the velocity is 
(to a good approximation) vertically uniform.  The shallow-shelf analog of \eqref{gliss.eq.stress_balance} is

\begin{equation}
  \label{gliss.eq.stress_balance_ssa}
  \begin{split}
    x: \quad \frac{\partial }{\partial x}\left( 2 \bar{\eta} H \left(2\frac{\partial u}{\partial x} +  \bar{\eta} H \frac{\partial v}{\partial y} \right) \right) 
    + \frac{\partial }{\partial y}\left[ \bar{\eta} H \left( \frac{\partial u}{\partial y} + \frac{\partial v}{\partial x} \right) \right] 
    = \rho g\frac{\partial s}{\partial x}, \\
    y: \quad \frac{\partial }{\partial y}\left( 2 \bar{\eta} H \left( 2\frac{\partial v}{\partial y} + \bar{\eta} H \frac{\partial u}{\partial x} \right) \right) 
    + \frac{\partial }{\partial x}\left[ \bar{\eta} H \left( \frac{\partial u}{\partial y} + \frac{\partial v}{\partial x} \right) \right] 
    = \rho g\frac{\partial s}{\partial y}.  \\
  \end{split}
\end{equation}

\noindent
The SSA equations in weak form resemble \eqref{gliss.eq.weak_form},
except that the internal stress terms are

\begin{equation}
  \label{gliss.eq.element_matrix_ssa}
  \begin{split}
    x: \int\limits_{\Omega }{2\bar{\eta} H \left( \frac{\partial {{\varphi }_{i}}}{\partial x}\left( 2\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{u}_{j}} \right\} + \left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{v}_{j}} \right\} \right) +
      \frac{\partial {{\varphi }_{i}}}{\partial y}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{u}_{j}} \right\}+\frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{v}_{j}} \right\} \right) \right)},  \\
    y: \int\limits_{\Omega }{2\bar{\eta} H \left( \frac{\partial {{\varphi }_{i}}}{\partial y}\left( 2\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{v}_{j}} \right\} + \left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{u}_{j}} \right\} \right) + 
      \frac{\partial {{\varphi }_{i}}}{\partial x}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial x} \right]\left\{ {{v}_{j}} \right\}+\frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial y} \right]\left\{ {{u}_{j}} \right\} \right) \right)}.  \\
  \end{split}
\end{equation}

\noindent
The resulting element matrices are similar to \eqref{gliss.eq.matrix_Kuu}--\eqref{gliss.eq.matrix_Kvv},
except that the terms containing $\frac{\partial {{\varphi }_{i}}}{\partial z}$ and
$\frac{\partial {{\varphi }_{j}}}{\partial z}$ are missing, and the viscosity term $\eta$
is replaced by $\bar{\eta} H$.  The effective viscosity is given by \eqref{gliss.eq.effective_viscosity},
but with \eqref{gliss.eq.effective_strain_rate} replaced by

\begin{equation}
  \label{gliss.eq.effective_strain_rate_ssa}
        {{\dot{\varepsilon }}^{2}}_{e} = 
        {{\dot{\varepsilon }}^{2}}_{xx} + {{\dot{\varepsilon }}^{2}}_{yy} + 
        {{\dot{\varepsilon }}_{xx}}{{\dot{\varepsilon }}_{yy}} + {{\dot{\varepsilon }}^{2}}_{xy}.
\end{equation}

\noindent
The integrals in \eqref{gliss.eq.element_matrix_ssa} are taken over 2D cells rather than 3D elements,
with basis functions and Jacobians given by \eqref{gliss.eq.basis_functions_2d}
and \eqref{gliss.eq.Jacobian_eval_2d}.

The basal boundary terms are handled as in the 3D Blatter-Pattyn approximation. 
The lateral boundary and gravitational forcing terms are computed initially in 3D
(as for the Blatter-Pattyn case), but then are summed in the vertical before being
inserted into the 2D right-hand vectors $b_u$ and $b_v$.  The solution procedure
is the same as for the 3D case, except that the problem has no vertical dimension.
When using the native PCG solver, the shallow-ice-based preconditioner is inappropriate
and the diagonal preconditioner should be used instead.  

In short, the SSA problem is analogous to the Blatter-Pattyn problem except for the
missing vertical terms.  The solution is generally much faster, because the SSA matrices
have roughly $3*nz$ times fewer nonzero entries than the Blatter-Pattyn matrices.
The factor of 3 arises from the fact that the BP equations at each level include
connections to the levels above and below, whereas the SSA equations
are solved for a single level.

\subsubsection{Shallow-ice approximation: Matrix form}

The shallow-ice equations follow from the Blatter-Pattyn equations if the horizontal-stress
terms are neglected.  The SIA analogs of \eqref{gliss.eq.stress_balance} are

\begin{equation}
  \label{gliss.eq.stress_balance_sia}
  \begin{split}
    x: \frac{\partial }{\partial z}\left( \eta \frac{\partial u}{\partial z} \right) = \rho g\frac{\partial s}{\partial x}, \\
    y: \frac{\partial }{\partial z}\left( \eta \frac{\partial v}{\partial z} \right) = \rho g\frac{\partial s}{\partial y}, \\
  \end{split}
\end{equation}

\noindent
leading to the following internal stress terms in weak form:

\begin{equation}
  \label{gliss.eq.element_matrix_sia}
  \begin{split}
    x: \int\limits_{\Omega } {2 \eta \frac{\partial {{\varphi }_{i}}}{\partial z}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial z} \right]\left\{ {{u}_{j}} \right\} \right) },  \\
    y: \int\limits_{\Omega } {2 \eta \frac{\partial {{\varphi }_{i}}}{\partial z}\left( \frac{1}{2}\left[ \frac{\partial {{\varphi }_{j}}}{\partial z} \right]\left\{ {{v}_{j}} \right\} \right) }.  \\
  \end{split}
\end{equation}

\noindent
These terms are integrated over elements using \eqref{gliss.eq.basis_functions}
and \eqref{gliss.eq.Jacobian_eval} for the 3D basis functions and Jacobians.
The resulting $8\text{x}8$ element matrices $K_{uu}$ and $K_{vv}$ link each node
to the eight nodes of the element, including itself.  Since there are no
horizontal stress terms, $K_{uv}$ = $K_{vu}$ = 0. In the expression for
effective viscosity, the effective strain rate is given by

\begin{equation}
  \label{gliss.eq.effective_strain_rate_sia}
        {\dot{\varepsilon }}^{2}_{e} = {\dot{\varepsilon }}^{2}_{xz} + {\dot{\varepsilon }}^{2}_{yz}.
\end{equation}

\noindent
The basal and lateral boundary conditions and gravitational loading are handled
just as for the Blatter-Pattyn case.

The resulting SIA global matrices contain about half as many nonzero terms as the BP matrices,
since $A_{uv}$ = $A_{vu}$ = 0.  But each ice column cannot be solved independently of the others;
rather, each node is linked to its horizontal neighbors by terms that arise during
element assembly.  As a result, the solution is not dramatically faster than solution
of the BP problem.  Thus the matrix-based shallow-ice solver can be useful for code testing
but is not practical for productions runs, since a practical SIA code solver should be many times
faster than a BP solver.  For production runs Glissade has an alternative solver,
described next.

\subsubsection{Shallow-ice approximation: Local form}

Glissade's local shallow-ice solver (in {\tt glissade\_velo\_sia.F90}),
is distinct from the finite-element solvers described above.
It is local in the sense that $u$ and $v$ in each ice column are found independently
of $u$ and $v$ in all other columns.
It resembles the Glide shallow-ice solver described in Section \ref{sc:glide_thickness_evolution}.
Glide, however, incorporates the velocity solution in a diffusion equation for ice thickness.
Glissade's local SIA solver computes $u$ and $v$ only, with
thickness evolving separately as described in Section \ref{sc:glissade-transport}.

The local SIA solver first computes the basal velocity given the basal traction coefficient $t_b$,
which is defined as in Glide:

\begin{equation}
  \mathbf{u_b} = t_b \mathbf{\tau_b}.
\end{equation}

\noindent
Note that $t_b = 1/\beta$, where the higher-order traction coefficient $\beta$ 
is defined as in \eqref{gliss.eq.beta_tau}.
There are several options for setting $t_b$: no sliding ($t_b = 0$);
uniform traction ($t_b = \mathrm{constant}$); uniform traction where basal water is present
(and no sliding elsewhere); and uniform traction where the bed is at the pressure melting point,
$T_b = T_{pmp}$ (and no sliding elsewhere).
As in Glide, the basal velocity is proportional to $t_b$ and the gravitational driving stress:

\begin{equation}
  \label{gliss.eq.velo_bed_sia}
        \mathbf{u_b} = -{{t}_{b}}{{\rho }_{i}} g \bar{H} \vec{\nabla s},
\end{equation}

\noindent
where $\bar{H}$ is the ice thickness interpolated to cell vertices,
and $\vec{\nabla s}$ is the surface slope at vertices.

To find the interior velocities, we
first compute a vertically integrated factor $c(\sigma)$ for each level at each cell vertex:

\begin{equation}
  \label{gliss.eq.vert_factor_sia}
  c(\sigma) = -2(\rho g)^n \bar{H}^{n+1} |\vec\nabla s|^{n-1} \int_1^{\sigma} \bar{A} \tilde{\sigma}^n d\tilde{\sigma},
\end{equation}

\noindent
where $\bar{A}$ is the flow factor interpolated to vertices,
and a tilde distinguishes $\sigma$ at a particular level from the integration variable $\tilde{\sigma}$.
(The same term appears in the Glide SIA calculation; see \eqref{kin.eq.horiz_diffusivity}.)
Discretized in the vertical, this becomes

\begin{equation}
  \label{gliss.eq.vert_factor_sia_discrete}
  c(k) = -2(\rho g)^n \bar{H}^{n+1} |\vec\nabla s|^{n-1} 
  \sum\limits_{l=nz-1}^{k} {{{{\bar{A}}}_{l}}}{{\left( \frac{{{\sigma }_{l}}+{{\sigma }_{l+1}}}{2} \right)}^{n}}\left( 
               {{\sigma }_{l+1}}-{{\sigma }_{l}} \right).
\end{equation}

\noindent
The factors $c(k)$ are then interpolated to cell edges, where the $u$ and $v$ 
components of velocity are computed as a function of the surface slope 
(also defined at cell edges):

\begin{equation}
  \label{gliss.eq.velo_interior_sia}
  \begin{split}
    {\Delta {u}_{E}}(k,i,j) = \sum\limits_{l=nz-1}^{k}{\left( \frac{c(k,i,j)+c(k,i,j-1)}{2} \right)\left( s(i+1,j)-s(i,j) \right)}, \\
    {\Delta {v}_{N}}(k,i,j) = \sum\limits_{l=nz-1}^{k}{\left( \frac{c(k,i,j)+c(k,i-1,j)}{2} \right)\left( s(i,j+1)-s(i,j) \right)}.
  \end{split}
\end{equation}

\noindent
Here, $\Delta{u_E}$ is the $u$ velocity component on the east edge of a cell, relative to the basal velocity,
and similarly for $\Delta{v_N}$ on the north edge of the cell.

Finally, we average $\Delta u_E$ and $\Delta v_N$ to vertices and add the bed velocities 
\eqref{gliss.eq.velo_bed_sia} to determine the velocity in the ice column at each vertex:

\begin{equation}
  \label{gliss.eq.velo_sia}
  \begin{split}
    u(k,i,j) = u_b(i,j) + \left( \frac{\Delta {{u}_{E}}(k,i,j) + \Delta {{u}_{E}}(k,i,j+1)}{2} \right), \\
    v(k,i,j) = v_b(i,j) + \left( \frac{\Delta {{v}_{N}}(k,i,j) + \Delta {{v}_{N}}(k,i+1,j)}{2} \right).
  \end{split}
\end{equation}

For serial problems there are no special advantages to using Glissade's local SIA solver 
in place of Glide.  Glissade's local SIA solver, however, can run on multiple processors, 
whereas Glide cannot.  For large SIA problems (e.g., the Greenland
ice sheet at $\sim\text{5 km}$ resolution), parallel Glissade can run faster.


